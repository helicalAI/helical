{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f5b3bc",
   "metadata": {},
   "source": [
    "This notebook goes over how to use `STATE` using `helical`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cbea7",
   "metadata": {},
   "source": [
    "# Download Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40e1b8",
   "metadata": {},
   "source": [
    "We start by using the helical downloader to obtain an example huggingface dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed699842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "INFO:datasets:PyTorch version 2.6.0 available.\n",
      "INFO:datasets:Polars version 1.33.0 available.\n",
      "INFO:helical.utils.downloader:Starting to download: 'https://huggingface.co/datasets/helical-ai/yolksac_human/resolve/main/data/17_04_24_YolkSacRaw_F158_WE_annots.h5ad?download=true'\n",
      "yolksac_human.h5ad: 100%|██████████| 553M/553M [00:04<00:00, 116MB/s]  \n"
     ]
    }
   ],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "from pathlib import Path\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_link(\n",
    "    Path(\"yolksac_human.h5ad\"),\n",
    "    \"https://huggingface.co/datasets/helical-ai/yolksac_human/resolve/main/data/17_04_24_YolkSacRaw_F158_WE_annots.h5ad?download=true\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e8491",
   "metadata": {},
   "source": [
    "# STATE Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ed3a3",
   "metadata": {},
   "source": [
    "Using the STATE model we can obtain single cell transcriptome embeddings. We first slice the dataset for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aab624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# load the data \n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"yolksac_human.h5ad\")\n",
    "# for demonstration we subset to 10 cells and 2000 genes\n",
    "adata = adata[:10, :2000].copy()\n",
    "\n",
    "print(adata.shape)\n",
    "n_cells = adata.n_obs\n",
    "print(n_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1c1b5",
   "metadata": {},
   "source": [
    "Initialise the model - this will download the relevant files needed in `.cache/helical/state/`. It will download the necessary files when run the first time so will take slightly longer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e73cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_embeddings:Using model checkpoint: /home/rasched/.cache/helical/models/state/state_embed/se600m_model_weights.pt\n",
      "INFO:helical.models.state.state_embeddings:Successfully loaded model\n"
     ]
    }
   ],
   "source": [
    "from helical.models.state import StateConfig    \n",
    "from helical.models.state import StateEmbed\n",
    "\n",
    "state_config = StateConfig(batch_size=16)\n",
    "state_embed = StateEmbed(configurer=state_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b4c72",
   "metadata": {},
   "source": [
    "We process the data by calling `state_embed.process_data` and pass this into `state_embed.get_embeddings` to get the final embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497b1f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_embeddings:Auto-detected gene column: var.index (overlap: 113/19790 protein embeddings, 5.7% of genes)\n",
      "INFO:/home/rasched/final_helical_with_state/helical/helical/models/state/model_dir/embed_utils/loader.py:113 genes mapped to embedding file (out of 2000)\n",
      "INFO:/home/rasched/final_helical_with_state/helical/helical/models/state/model_dir/embed_utils/loader.py:113 genes mapped to embedding file (out of 2000)\n",
      "Encoding: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2058)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_data = state_embed.process_data(adata=adata)\n",
    "embeddings = state_embed.get_embeddings(processed_data)\n",
    "\n",
    "# note that the STATE model returns a numpy array of shape (n_cells, 1024)\n",
    "print(embeddings.shape)\n",
    "print(type(embeddings))\n",
    "\n",
    "# store the embeddings in adata.obsm['state_emb']\n",
    "adata.obsm['state_emb'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861511f",
   "metadata": {},
   "source": [
    "# STATE Perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43c1bb",
   "metadata": {},
   "source": [
    "To use the perturbation model you can either pass in embeddings by specifiyng the `embed_key` arguement in `stateConfig` or use the deafult `None` value in which case the expression values are used (`adata.X`).\n",
    "\n",
    "For use of previous embeddings, the `embed_key` must exist in `adata.obsm[<embed_key>]` otherwise an error will be thrown. When set to `None` the model uses `adata.X`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6cd96",
   "metadata": {},
   "source": [
    "Let's create some dummy data for the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abafa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# some default control and non-control perturbations\n",
    "perturbations = [\n",
    "    \"[('DMSO_TF', 0.0, 'uM')]\",  # Control\n",
    "    \"[('Aspirin', 0.5, 'uM')]\",\n",
    "    \"[('Dexamethasone', 1.0, 'uM')]\",\n",
    "]\n",
    "\n",
    "n_cells = adata.n_obs\n",
    "# we assign perturbations to cells randomly\n",
    "adata.obs['target_gene'] = np.random.choice(perturbations, size=n_cells)\n",
    "adata.obs['cell_type'] = adata.obs['LVL1']  # Use your cell type column\n",
    "# we can also add a batch variable to take into account batch effects\n",
    "batch_labels = np.random.choice(['batch_1', 'batch_2', 'batch_3', 'batch_4'], size=n_cells)\n",
    "adata.obs['batch_var'] = batch_labels\n",
    "\n",
    "config = StateConfig(\n",
    "    embed_key=None,\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    output_path=\"yolksac_perturbed.h5ad\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c11cfb",
   "metadata": {},
   "source": [
    "Now we can run the perturbation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab93647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_transition:Using checkpoint: /home/rasched/.cache/helical/models/state/state_transition/final.ckpt\n",
      "INFO:helical.models.state.model_dir.perturb_utils.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:helical.models.state.state_transition:Model device: cuda:0\n",
      "INFO:helical.models.state.state_transition:Model cell_set_len (max sequence length): 256\n",
      "INFO:helical.models.state.state_transition:Model uses batch encoder: True\n",
      "INFO:helical.models.state.state_transition:Model output space: gene\n",
      "INFO:helical.models.state.state_transition:Using adata.X as input features\n",
      "INFO:helical.models.state.state_transition:Warning: 10 / 10 batch labels not found in saved mapping;using index 0 as fallback.\n",
      "INFO:helical.models.state.state_transition:Cells: total=10, control=5, non-control=5\n",
      "INFO:helical.models.state.state_transition:Running virtual experiment (homogeneous per-perturbation forward passes; controls included)...\n",
      "Group ERYTHROID:   0%|          | 0/2 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group ERYTHROID) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group ERYTHROID: 100%|██████████| 2/2 [00:00<00:00, 58.08it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "Group MYELOID:   0%|          | 0/3 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group MYELOID) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group MYELOID: 100%|██████████| 3/3 [00:00<00:00, 331.94it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "Group STROMA:   0%|          | 0/3 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group STROMA) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group STROMA: 100%|██████████| 3/3 [00:00<00:00, 352.10it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "... storing 'target_gene' as categorical\n",
      "... storing 'batch_var' as categorical\n",
      "INFO:helical.models.state.state_transition:--Complete--\n",
      "Input cells: 10, Control simulated: 5, Treated simulated: 5\n",
      "INFO:helical.models.state.state_transition:Wrote predictions to adata.obsm.perturbed_embeds in output file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000)\n"
     ]
    }
   ],
   "source": [
    "from helical.models.state import StateTransitionModel\n",
    "\n",
    "state_transition = StateTransitionModel(configurer=config)\n",
    "\n",
    "# again we process the data and get the perturbed embeddings\n",
    "processed_data = state_transition.process_data(adata)\n",
    "perturbed_embeds = state_transition.get_embeddings(processed_data)\n",
    "\n",
    "print(perturbed_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582345dd",
   "metadata": {},
   "source": [
    "# Finetuning STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e835b83",
   "metadata": {},
   "source": [
    "We can finetune the STATE perturbation embeddings using an additional head for downstream classification and regression. Below is a dummy example using data above to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8c1261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 unique cell types:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_transition:Using checkpoint: /home/rasched/.cache/helical/models/state/state_transition/final.ckpt\n",
      "INFO:helical.models.state.model_dir.perturb_utils.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:helical.models.state.state_transition:Model device: cuda:0\n",
      "INFO:helical.models.state.state_transition:Model cell_set_len (max sequence length): 256\n",
      "INFO:helical.models.state.state_transition:Model uses batch encoder: True\n",
      "INFO:helical.models.state.state_transition:Model output space: gene\n",
      "INFO:helical.models.state.fine_tuning_model:Backbone frozen: True\n",
      "INFO:helical.models.state.fine_tuning_model:Processing data for state model fine-tuning.\n",
      "INFO:helical.models.state.state_transition:Using adata.X as input features\n",
      "INFO:helical.models.state.state_transition:Warning: 10 / 10 batch labels not found in saved mapping;using index 0 as fallback.\n",
      "INFO:helical.models.state.state_transition:Cells: total=10, control=5, non-control=5\n",
      "INFO:helical.models.state.state_transition:Running virtual experiment (homogeneous per-perturbation forward passes; controls included)...\n",
      "Group ERYTHROID:   0%|          | 0/2 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group ERYTHROID) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group ERYTHROID: 100%|██████████| 2/2 [00:00<00:00, 194.81it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "Group MYELOID:   0%|          | 0/3 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group MYELOID) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group MYELOID: 100%|██████████| 3/3 [00:00<00:00, 83.62it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "Group STROMA:   0%|          | 0/3 [00:00<?, ?it/s, Pert: [('Dexamethasone', 1.0, ]INFO:helical.models.state.state_transition:  (group STROMA) pert '[('Dexamethasone', 1.0, 'uM')]' not in mapping; using control fallback one-hot.\n",
      "Group STROMA: 100%|██████████| 3/3 [00:00<00:00, 173.59it/s, Pert: [('Dexamethasone', 1.0, ]\n",
      "INFO:helical.models.state.state_transition:--Complete--\n",
      "Input cells: 10, Control simulated: 5, Treated simulated: 5\n",
      "INFO:helical.models.state.state_transition:Wrote predictions to adata.obsm.perturbed_embeds in output file\n",
      "INFO:helical.models.state.fine_tuning_model:Successfully processed the data for state model fine-tuning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {'MYELOID': 0, 'STROMA': 1, 'ERYTHROID': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning: epoch 1/1: 100%|██████████| 2/2 [00:00<00:00, 56.81it/s, loss=1.15]\n",
      "INFO:helical.models.state.fine_tuning_model:Fine-Tuning Complete. Epochs: 1\n"
     ]
    }
   ],
   "source": [
    "from helical.models.state import StateFineTuningModel\n",
    "\n",
    "# Dummy cell types and labels for demonstration\n",
    "cell_types = list(adata.obs['LVL1'])\n",
    "label_set = set(cell_types)\n",
    "print(f\"Found {len(label_set)} unique cell types:\")\n",
    "\n",
    "config = StateConfig(\n",
    "    embed_key=None,\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "# Create the fine-tuning model - we use a classification head for demonstration\n",
    "model = StateFineTuningModel(\n",
    "    configurer=config, \n",
    "    fine_tuning_head=\"classification\", \n",
    "    output_size=len(label_set),\n",
    ")\n",
    "\n",
    "# Process the data for training - returns a dataset object\n",
    "dataset = model.process_data(adata)\n",
    "\n",
    "# Create a dictionary mapping the classes to unique integers for training\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "# Convert cell type labels to integers\n",
    "cell_type_labels = [class_id_dict[ct] for ct in cell_types]\n",
    "\n",
    "print(f\"Class mapping: {class_id_dict}\")\n",
    "\n",
    "# Fine-tune\n",
    "model.train(train_input_data=dataset, train_labels=cell_type_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53936df",
   "metadata": {},
   "source": [
    "# Training STATE for the Virtual Cell Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be814ae",
   "metadata": {},
   "source": [
    "We use data from the Virtual Cell Challenge for model training and downstream inference. For this we require the VCC dataset as in the colab notebook by the authors. See the relevant code snippet for the entire dataset in the below colab notebook:\n",
    "\n",
    "[STATE Colab Notebook](https://colab.research.google.com/drive/1QKOtYP7bMpdgDJEipDxaJqOchv7oQ-_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e7ad8",
   "metadata": {},
   "source": [
    "For demonstration we have created a subset of the data. We also need to change the filepath in `starter.toml` to point to the correct dataset location (see top of file), but this is done below in the code. Start by downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83609bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:helical.utils.downloader:File size mismatch: local 197, remote 465\n",
      "WARNING:helical.utils.downloader:File '/home/rasched/.cache/helical/models/state/sample_vcc_data/starter.toml' is corrupted or invalid. Deleting and re-downloading.\n",
      "INFO:helical.utils.downloader:Downloading 'state/sample_vcc_data/starter.toml'\n",
      "INFO:helical.utils.downloader:Starting to download: 'https://helicalpackage.s3.eu-west-2.amazonaws.com/state/sample_vcc_data/starter.toml'\n",
      "starter.toml: 100%|██████████| 465/465 [00:00<00:00, 4.19MB/s]\n",
      "INFO:helical.utils.downloader:File saved to: '/home/rasched/.cache/helical/models/state/sample_vcc_data/starter.toml'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[datasets]\\nreplogle_h1 = \"/home/rasched/.cache/helical/models/state/sample_vcc_data/{rpe1_mini,hepg2_mini}.h5\"\\n\\n[training]\\nreplogle_h1 = \"train\"\\n\\n[zeroshot]\\n\"replogle_h1.hepg2\" = \"test\"\\n\\n[fewshot]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "from helical.constants.paths import CACHE_DIR_HELICAL\n",
    "import toml\n",
    "from pathlib import Path\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_name(\"state/sample_vcc_data/config.yaml\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/starter.toml\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/gene_names.csv\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/ESM2_pert_features.pt\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/hepg2_mini.h5\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/rpe1_mini.h5\")\n",
    "downloader.download_via_name(\"state/sample_vcc_data/test.h5ad\")\n",
    "\n",
    "toml.dump({**toml.load(open(Path(CACHE_DIR_HELICAL, \"state/sample_vcc_data/starter.toml\"))),**{\"datasets\": {\"replogle_h1\": str(Path(CACHE_DIR_HELICAL, \"state/sample_vcc_data\").absolute() / \"{rpe1_mini,hepg2_mini}.h5\")}},},open(Path(CACHE_DIR_HELICAL, \"state/sample_vcc_data/starter.toml\"), \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974174ac",
   "metadata": {},
   "source": [
    "We use the `stateTransitionTrainModel` class and initialise training configurations using the `config.yaml` file in the sample directory. You can edit these based on your training preferences. Currently this is set to one epoch for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23307fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 42\n",
      "INFO:lightning.fabric.utilities.seed:Seed set to 42\n",
      "WARNING:cell_load.config:Dataset path does not exist: /home/rasched/.cache/helical/models/state/sample_vcc_data/{rpe1_mini,hepg2_mini}.h5\n",
      "INFO:cell_load.config:Configuration validation passed\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:Initializing DataModule: batch_size=16, workers=4, random_seed=42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rasched/.cache/helical/models/state/sample_vcc_data/{rpe1_mini,hepg2_mini}.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cell_load.data_modules.perturbation_dataloader:Set 2 missing perturbations to zero vectors.\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:Loaded custom perturbation featurizations for 19792 perturbations.\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:Processing dataset replogle_h1:\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:  - Training dataset: True\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:  - Zeroshot cell types: ['hepg2']\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:  - Fewshot cell types: []\n",
      "Processing replogle_h1:   0%|          | 0/2 [00:00<?, ?it/s]WARNING:cell_load.dataset._perturbation:No cell barcode information found in /home/rasched/.cache/helical/models/state/sample_vcc_data/rpe1_mini.h5. Generating generic barcodes.\n",
      "Processing replogle_h1:   0%|          | 0/2 [00:00<?, ?it/s]WARNING:cell_load.dataset._perturbation:No cell barcode information found in /home/rasched/.cache/helical/models/state/sample_vcc_data/hepg2_mini.h5. Generating generic barcodes.\n",
      "Processing replogle_h1: 100%|██████████| 2/2 [00:00<00:00, 386.55it/s]\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:\n",
      "\n",
      "INFO:cell_load.data_modules.perturbation_dataloader:Done! Train / Val / Test splits: 1 / 0 / 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed rpe1_mini: 100 train, 0 val, 0 test\n",
      "Processed hepg2_mini: 0 train, 0 val, 100 test\n",
      "Model created. Estimated params size: 0.61 GB and 650505936 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_train:Loggers and callbacks set up.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:helical.models.state.state_train:Starting trainer fit.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO: \n",
      "  | Name                 | Type                    | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | loss_fn              | SamplesLoss             | 0      | train\n",
      "1 | pert_encoder         | Sequential              | 4.8 M  | train\n",
      "2 | basal_encoder        | Linear                  | 12.2 M | train\n",
      "3 | transformer_backbone | LlamaBidirectionalModel | 50.4 M | train\n",
      "4 | project_out          | Sequential              | 13.5 M | train\n",
      "5 | final_down_then_up   | Sequential              | 81.7 M | train\n",
      "6 | relu                 | ReLU                    | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "141 M     Trainable params\n",
      "21.5 M    Non-trainable params\n",
      "162 M     Total params\n",
      "650.506   Total estimated model params size (MB)\n",
      "86        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name                 | Type                    | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | loss_fn              | SamplesLoss             | 0      | train\n",
      "1 | pert_encoder         | Sequential              | 4.8 M  | train\n",
      "2 | basal_encoder        | Linear                  | 12.2 M | train\n",
      "3 | transformer_backbone | LlamaBidirectionalModel | 50.4 M | train\n",
      "4 | project_out          | Sequential              | 13.5 M | train\n",
      "5 | final_down_then_up   | Sequential              | 81.7 M | train\n",
      "6 | relu                 | ReLU                    | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "141 M     Trainable params\n",
      "21.5 M    Non-trainable params\n",
      "162 M     Total params\n",
      "650.506   Total estimated model params size (MB)\n",
      "86        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer built successfully\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cell_load.data_modules.samplers:Creating perturbation batch sampler with metadata caching (using codes)...\n",
      "INFO:cell_load.data_modules.samplers:Total # cells 100. Cell set size mean / std before resampling: 4.76 / 11.85.\n",
      "INFO:cell_load.data_modules.samplers:Creating meta-batches with cell_sentence_len=128...\n",
      "INFO:cell_load.data_modules.samplers:Of all batches, 0 were full and 21 were partial.\n",
      "INFO:cell_load.data_modules.samplers:Sampler created with 2 batches in 0.00 seconds.\n",
      "INFO:cell_load.data_modules.samplers:Of all batches, 0 were full and 21 were partial.\n",
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:377: You have overridden `transfer_batch_to_device` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2048. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 15.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 640. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cell_load.data_modules.samplers:Creating perturbation batch sampler with metadata caching (using codes)...\n",
      "INFO:cell_load.data_modules.samplers:Total # cells 100. Cell set size mean / std before resampling: 4.55 / 12.04.\n",
      "INFO:cell_load.data_modules.samplers:Creating meta-batches with cell_sentence_len=128...\n",
      "INFO:cell_load.data_modules.samplers:Of all batches, 0 were full and 22 were partial.\n",
      "INFO:cell_load.data_modules.samplers:Sampler created with 2 batches in 0.00 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cell_load.data_modules.samplers:Of all batches, 0 were full and 22 were partial.\n",
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2/2 [00:01<00:00,  1.28it/s, v_num=0]\n",
      "Training completed, saving final checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cell_load.data_modules.samplers:Creating perturbation batch sampler with metadata caching (using codes)...\n",
      "INFO:cell_load.data_modules.samplers:Total # cells 100. Cell set size mean / std before resampling: 4.76 / 11.85.\n",
      "INFO:cell_load.data_modules.samplers:Creating meta-batches with cell_sentence_len=128...\n",
      "INFO:cell_load.data_modules.samplers:Of all batches, 21 were full and 0 were partial.\n",
      "INFO:cell_load.data_modules.samplers:Sampler created with 21 batches in 0.00 seconds.\n",
      "INFO:helical.models.state.state_train:Loading model from sample_run/first_run/final.ckpt\n",
      "INFO:helical.models.state.state_train:Model loaded successfully.\n",
      "INFO:helical.models.state.state_train:Generating predictions on test set using manual loop...\n",
      "Predicting:   0%|          | 0/21 [00:00<?, ?batch/s]INFO:cell_load.data_modules.samplers:Of all batches, 21 were full and 0 were partial.\n",
      "Predicting: 100%|██████████| 21/21 [00:01<00:00, 17.99batch/s]\n",
      "INFO:helical.models.state.state_train:Creating anndatas from predictions from manual loop...\n",
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/functools.py:909: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "\n",
      "WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/functools.py:909: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "\n",
      "... storing 'target_gene' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "... storing 'batch_var' as categorical\n",
      "... storing 'ctrl_cell_barcode' as categorical\n",
      "... storing 'target_gene' as categorical\n",
      "... storing 'cell_type' as categorical\n",
      "... storing 'batch_var' as categorical\n",
      "... storing 'ctrl_cell_barcode' as categorical\n",
      "INFO:helical.models.state.state_train:Saved adata_pred to sample_run/adata_pred.h5ad\n",
      "INFO:helical.models.state.state_train:Saved adata_real to sample_run/adata_real.h5ad\n",
      "INFO:helical.models.state.state_train:Computing metrics using cell-eval...\n",
      "WARNING:helical.models.state.model_dir.train_utils.evaluator:Output directory sample_run already exists, potential overwrite occurring\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Input is found to be log-normalized already - skipping transformation.\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Input is found to be log-normalized already - skipping transformation.\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Computing DE for real data\n",
      "INFO:pdex._single_cell:Precomputing masks for each target gene\n",
      "Identifying target masks: 100%|██████████| 21/21 [00:00<00:00, 38564.09it/s]\n",
      "INFO:pdex._single_cell:Precomputing variable indices for each feature\n",
      "Identifying variable indices: 100%|██████████| 18080/18080 [00:00<00:00, 5863075.33it/s]\n",
      "INFO:pdex._single_cell:Creating shared memory memory matrix for parallel computing\n",
      "INFO:pdex._single_cell:Creating generator of all combinations: N=379680\n",
      "INFO:pdex._single_cell:Creating generator of all batches: N=186\n",
      "INFO:pdex._single_cell:Initializing parallel processing pool\n",
      "INFO:pdex._single_cell:Processing batches\n",
      "Processing batches: 100%|██████████| 186/186 [00:04<00:00, 45.63it/s]\n",
      "INFO:pdex._single_cell:Flattening results\n",
      "INFO:pdex._single_cell:Closing shared memory pool\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Writing real DE results to: hepg2_real_de.csv\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Computing DE for pred data\n",
      "INFO:pdex._single_cell:Precomputing masks for each target gene\n",
      "Identifying target masks: 100%|██████████| 21/21 [00:00<00:00, 35316.91it/s]\n",
      "INFO:pdex._single_cell:Precomputing variable indices for each feature\n",
      "Identifying variable indices: 100%|██████████| 18080/18080 [00:00<00:00, 7383216.47it/s]\n",
      "INFO:pdex._single_cell:Creating shared memory memory matrix for parallel computing\n",
      "INFO:pdex._single_cell:Creating generator of all combinations: N=379680\n",
      "INFO:pdex._single_cell:Creating generator of all batches: N=186\n",
      "INFO:pdex._single_cell:Initializing parallel processing pool\n",
      "INFO:pdex._single_cell:Processing batches\n",
      "Processing batches: 100%|██████████| 186/186 [00:04<00:00, 38.73it/s]\n",
      "INFO:pdex._single_cell:Flattening results\n",
      "INFO:pdex._single_cell:Closing shared memory pool\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Writing pred DE results to: hepg2_pred_de.csv\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'overlap_at_N'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'overlap_at_50'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'overlap_at_100'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'overlap_at_200'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'overlap_at_500'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'precision_at_N'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'precision_at_50'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'precision_at_100'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'precision_at_200'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'precision_at_500'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'de_spearman_sig'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'de_direction_match'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'de_spearman_lfc_sig'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'de_sig_genes_recall'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'de_nsig_counts'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'pr_auc'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'roc_auc'\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'pearson_delta'\n",
      "INFO:helical.models.state.model_dir.train_utils._types._anndata:Building pseudobulk embeddings for real anndata on: .X\n",
      "INFO:helical.models.state.model_dir.train_utils._types._anndata:Building pseudobulk embeddings for predicted anndata on: .X\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 3472.25it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'mse'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 5473.45it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'mae'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 5218.74it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'mse_delta'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 6366.10it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'mae_delta'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 6225.31it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'discrimination_score_l1'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 23314.64it/s]\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 32451.09it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'discrimination_score_l2'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 28426.32it/s]\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 31726.96it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils._pipeline._runner:Computing metric 'discrimination_score_cosine'\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 22274.58it/s]\n",
      "Iterating over perturbations...: 100%|██████████| 20/20 [00:00<00:00, 25236.49it/s]\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Writing perturbation level metrics to sample_run/hepg2_results.csv\n",
      "INFO:helical.models.state.model_dir.train_utils.evaluator:Writing aggregate metrics to sample_run/hepg2_agg_results.csv\n"
     ]
    }
   ],
   "source": [
    "# we can then train the model and perform inference on a held out test set\n",
    "from helical.models.state import StateTransitionTrainModel\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "train_configs = OmegaConf.load(Path(CACHE_DIR_HELICAL, \"state/sample_vcc_data/config.yaml\"))\n",
    "# set the correct paths for the data\n",
    "train_configs.data.kwargs.toml_config_path = str(CACHE_DIR_HELICAL / \"state/sample_vcc_data/starter.toml\")\n",
    "train_configs.data.kwargs.perturbation_features_file = str(CACHE_DIR_HELICAL / \"state/sample_vcc_data/ESM2_pert_features.pt\")\n",
    "\n",
    "state_train = StateTransitionTrainModel(configurer=train_configs)\n",
    "state_train.train() \n",
    "state_train.predict() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb512a0",
   "metadata": {},
   "source": [
    "The trained model will be saved to the `sample_vcc_data/first_run` directory, alongside the necessary files and checkpoints to intialise a new model. We can initialise `stateTransitionModel` as before and run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be67236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_transition:Using checkpoint: sample_run/first_run/final.ckpt\n",
      "INFO:helical.models.state.state_transition:Model device: cpu\n",
      "INFO:helical.models.state.state_transition:Model cell_set_len (max sequence length): 128\n",
      "INFO:helical.models.state.state_transition:Model uses batch encoder: False\n",
      "INFO:helical.models.state.state_transition:Model output space: all\n",
      "INFO:helical.models.state.state_transition:Grouping by cell type column: cell_type\n",
      "INFO:helical.models.state.state_transition:Using adata.X as input features\n",
      "INFO:helical.models.state.state_transition:Cells: total=100, control=50, non-control=50\n",
      "INFO:helical.models.state.state_transition:Running virtual experiment (homogeneous per-perturbation forward passes; controls included)...\n",
      "Group H1: 100%|██████████| 26/26 [00:00<00:00, 87.77it/s, Pert: non-targeting           ]\n",
      "INFO:helical.models.state.state_transition:--Complete--\n",
      "Input cells: 100, Control simulated: 50, Treated simulated: 50\n",
      "INFO:helical.models.state.state_transition:Wrote predictions to adata.obsm.perturbed_embeds in output file\n"
     ]
    }
   ],
   "source": [
    "from helical.models.state import StateTransitionModel\n",
    "from helical.models.state import StateConfig\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(Path(CACHE_DIR_HELICAL, \"state/sample_vcc_data/test.h5ad\"))\n",
    "\n",
    "state_config = StateConfig(\n",
    "    output_path = \"sample_run/prediction.h5ad\",\n",
    "    perturb_dir = \"sample_run/first_run\",\n",
    "    pert_col = \"target_gene\",\n",
    ")\n",
    "\n",
    "state_transition = StateTransitionModel(configurer=state_config)\n",
    "processed_data = state_transition.process_data(adata)\n",
    "embeds = state_transition.get_embeddings(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45529597",
   "metadata": {},
   "source": [
    "Now you can use the `cell-eval` package to create a submission to the Virtual Cell Challenge (generates a `.vcc` file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a629a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cell-eval in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (0.5.43)\n",
      "Requirement already satisfied: igraph>=0.11.8 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (0.11.9)\n",
      "Requirement already satisfied: pdex>=0.1.20 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (0.1.24)\n",
      "Requirement already satisfied: polars>=1.30.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (1.33.0)\n",
      "Requirement already satisfied: pyarrow>=18.0.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (6.0.2)\n",
      "Requirement already satisfied: scanpy>=1.10.3 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (1.11.4)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from cell-eval) (4.67.1)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from igraph>=0.11.8->cell-eval) (1.7.0)\n",
      "Requirement already satisfied: adpbulk>=0.1.4 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (0.1.4)\n",
      "Requirement already satisfied: anndata>=0.9.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (0.12.2)\n",
      "Requirement already satisfied: numba>=0.61.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.0.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (2.2.2)\n",
      "Requirement already satisfied: pydeseq2>=0.5.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.15.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pdex>=0.1.20->cell-eval) (1.16.2)\n",
      "Requirement already satisfied: pytest in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from adpbulk>=0.1.4->pdex>=0.1.20->cell-eval) (8.4.1)\n",
      "Requirement already satisfied: array-api-compat>=1.7.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (1.12.0)\n",
      "Requirement already satisfied: h5py>=3.8 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (3.14.0)\n",
      "Requirement already satisfied: legacy-api-wrap in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (1.4.1)\n",
      "Requirement already satisfied: natsort in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (8.4.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /home/rasched/.local/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (25.0)\n",
      "Requirement already satisfied: zarr!=3.0.*,>=2.18.7 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from anndata>=0.9.0->pdex>=0.1.20->cell-eval) (3.1.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from numba>=0.61.2->pdex>=0.1.20->cell-eval) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/rasched/.local/lib/python3.11/site-packages (from pandas>=2.0.0->pdex>=0.1.20->cell-eval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pandas>=2.0.0->pdex>=0.1.20->cell-eval) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pandas>=2.0.0->pdex>=0.1.20->cell-eval) (2025.2)\n",
      "Requirement already satisfied: formulaic>=1.0.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.7.1)\n",
      "Requirement already satisfied: formulaic-contrasts>=0.2.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.0.0)\n",
      "Requirement already satisfied: matplotlib>=3.6.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (3.10.6)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from formulaic>=1.0.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.17 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from formulaic>=1.0.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/rasched/.local/lib/python3.11/site-packages (from formulaic>=1.0.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from formulaic>=1.0.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.17.3)\n",
      "Requirement already satisfied: session-info in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from formulaic-contrasts>=0.2.0->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from matplotlib>=3.6.2->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/rasched/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pdex>=0.1.20->cell-eval) (1.17.0)\n",
      "Requirement already satisfied: joblib in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (1.5.2)\n",
      "Requirement already satisfied: networkx>=2.7.1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (3.5)\n",
      "Requirement already satisfied: patsy!=1.0.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (1.0.1)\n",
      "Requirement already satisfied: pynndescent>=0.5.13 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (0.5.13)\n",
      "Requirement already satisfied: seaborn>=0.13.2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (0.13.2)\n",
      "Requirement already satisfied: session-info2 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (0.2.1)\n",
      "Requirement already satisfied: statsmodels>=0.14.5 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (0.14.5)\n",
      "Requirement already satisfied: umap-learn>=0.5.6 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scanpy>=1.10.3->cell-eval) (0.5.9.post2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from scikit-learn>=1.1.0->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (3.6.0)\n",
      "Requirement already satisfied: donfig>=0.8 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from zarr!=3.0.*,>=2.18.7->anndata>=0.9.0->pdex>=0.1.20->cell-eval) (0.8.1.post1)\n",
      "Requirement already satisfied: numcodecs>=0.14 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.9.0->pdex>=0.1.20->cell-eval) (0.16.2)\n",
      "Requirement already satisfied: crc32c>=2.7 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.9.0->pdex>=0.1.20->cell-eval) (2.7.1)\n",
      "Requirement already satisfied: iniconfig>=1 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pytest->adpbulk>=0.1.4->pdex>=0.1.20->cell-eval) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from pytest->adpbulk>=0.1.4->pdex>=0.1.20->cell-eval) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /home/rasched/.local/lib/python3.11/site-packages (from pytest->adpbulk>=0.1.4->pdex>=0.1.20->cell-eval) (2.19.2)\n",
      "Requirement already satisfied: stdlib_list in /home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages (from session-info->formulaic-contrasts>=0.2.0->pydeseq2>=0.5.1->pdex>=0.1.20->cell-eval) (0.11.1)\n",
      "INFO:cell_eval._cli._prep:Reading input anndata\n",
      "INFO:cell_eval._cli._prep:Reading gene list\n",
      "INFO:cell_eval._cli._prep:Preparing anndata\n",
      "INFO:cell_eval._cli._prep:Using 32-bit float encoding\n",
      "INFO:cell_eval._cli._prep:Setting data to sparse if not already\n",
      "INFO:cell_eval._cli._prep:Simplifying obs dataframe\n",
      "INFO:cell_eval._cli._prep:Simplifying var dataframe\n",
      "INFO:cell_eval._cli._prep:Creating final minimal AnnData object\n",
      "INFO:cell_eval._cli._prep:Applying normlog transformation if required\n",
      "INFO:cell_eval._evaluator:Input is found to be log-normalized already - skipping transformation.\n",
      "INFO:cell_eval._cli._prep:Writing h5ad output to /tmp/tmpvilc9i_j/pred.h5ad\n",
      "INFO:cell_eval._cli._prep:Zstd compressing /tmp/tmpvilc9i_j/pred.h5ad\n",
      "/tmp/tmpvilc9i_j/pred.h5ad : 19.31%   (  7.50 MiB =>   1.45 MiB, /tmp/tmpvilc9i_j/pred.h5ad.zst) \n",
      "INFO:cell_eval._cli._prep:Packing files into sample_run/prediction.prep.vcc\n",
      "INFO:cell_eval._cli._prep:Done\n"
     ]
    }
   ],
   "source": [
    "gene_file = CACHE_DIR_HELICAL / \"state/sample_vcc_data/gene_names.csv\"\n",
    "input_file = \"sample_run/prediction.h5ad\"\n",
    "\n",
    "! pip install cell-eval\n",
    "! cell-eval prep -i {input_file} -g {gene_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3902e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import numpy as np\n",
    "\n",
    "# def create_balanced_mini_dataset(input_path, output_path, n_cells=100):\n",
    "#     \"\"\"\n",
    "#     Create a mini dataset that preserves both control and perturbation cells\n",
    "#     \"\"\"\n",
    "#     adata = sc.read_h5ad(input_path)\n",
    "    \n",
    "#     # Find control and perturbation cells\n",
    "#     control_mask = adata.obs['target_gene'] == 'non-targeting'\n",
    "#     pert_mask = ~control_mask\n",
    "    \n",
    "#     control_indices = np.where(control_mask)[0]\n",
    "#     pert_indices = np.where(pert_mask)[0]\n",
    "    \n",
    "#     print(f\"Original: {len(control_indices)} control, {len(pert_indices)} perturbation cells\")\n",
    "    \n",
    "#     # Sample proportionally\n",
    "#     n_control = min(n_cells // 2, len(control_indices))\n",
    "#     n_pert = min(n_cells - n_control, len(pert_indices))\n",
    "    \n",
    "#     # If we need more cells, fill with the remaining type\n",
    "#     if n_control + n_pert < n_cells:\n",
    "#         if len(control_indices) > n_control:\n",
    "#             n_control = min(n_cells, len(control_indices))\n",
    "#             n_pert = 0\n",
    "#         elif len(pert_indices) > n_pert:\n",
    "#             n_pert = min(n_cells, len(pert_indices))\n",
    "#             n_control = 0\n",
    "    \n",
    "#     # Sample indices\n",
    "#     np.random.seed(42)\n",
    "#     sampled_control = np.random.choice(control_indices, size=n_control, replace=False) if n_control > 0 else np.array([])\n",
    "#     sampled_pert = np.random.choice(pert_indices, size=n_pert, replace=False) if n_pert > 0 else np.array([])\n",
    "    \n",
    "#     # Combine and create new dataset\n",
    "#     all_sampled = np.concatenate([sampled_control, sampled_pert])\n",
    "#     adata_mini = adata[all_sampled, :].copy()\n",
    "    \n",
    "#     print(f\"Mini dataset: {len(sampled_control)} control, {len(sampled_pert)} perturbation cells\")\n",
    "#     print(f\"Total: {adata_mini.shape}\")\n",
    "    \n",
    "#     adata_mini.write_h5ad(output_path)\n",
    "#     return adata_mini\n",
    "\n",
    "# # Create a balanced mini dataset\n",
    "# mini_val = create_balanced_mini_dataset(\"competition_support_set/competition_val_template.h5ad\", \"competition_support_set/mini_val_balanced.h5ad\", n_cells=100)\n",
    "\n",
    "# import scanpy as sc\n",
    "# import anndata as ad\n",
    "\n",
    "# def truncate_adata_file_complete(input_path, output_path, max_cells=100, max_genes=None):\n",
    "#     \"\"\"\n",
    "#     Truncate an AnnData file and handle ALL fields properly\n",
    "#     \"\"\"\n",
    "#     print(f\"Loading {input_path}...\")\n",
    "#     adata = sc.read_h5ad(input_path)\n",
    "    \n",
    "#     print(f\"Original shape: {adata.shape}\")\n",
    "#     print(f\"Original obsm keys: {list(adata.obsm.keys())}\")\n",
    "    \n",
    "#     # Truncate cells\n",
    "#     if max_cells and adata.n_obs > max_cells:\n",
    "#         print(f\"Truncating to {max_cells} cells...\")\n",
    "        \n",
    "#         # Truncate main data\n",
    "#         adata = adata[:max_cells, :].copy()\n",
    "        \n",
    "#         # Manually truncate obsm fields that might not be handled properly\n",
    "#         for key in adata.obsm.keys():\n",
    "#             matrix = adata.obsm[key]\n",
    "#             if hasattr(matrix, 'shape') and len(matrix.shape) > 0:\n",
    "#                 if matrix.shape[0] > max_cells:\n",
    "#                     print(f\"Truncating obsm['{key}'] from {matrix.shape} to ({max_cells}, {matrix.shape[1] if len(matrix.shape) > 1 else 'N/A'})\")\n",
    "#                     adata.obsm[key] = matrix[:max_cells]\n",
    "    \n",
    "#     # Truncate genes (optional)\n",
    "#     if max_genes and adata.n_vars > max_genes:\n",
    "#         print(f\"Truncating to {max_genes} genes...\")\n",
    "        \n",
    "#         # Truncate main data\n",
    "#         adata = adata[:, :max_genes].copy()\n",
    "        \n",
    "#         # Manually truncate varm fields\n",
    "#         for key in adata.varm.keys():\n",
    "#             matrix = adata.varm[key]\n",
    "#             if hasattr(matrix, 'shape') and len(matrix.shape) > 0:\n",
    "#                 if matrix.shape[0] > max_genes:\n",
    "#                     print(f\"Truncating varm['{key}'] from {matrix.shape} to ({max_genes}, {matrix.shape[1] if len(matrix.shape) > 1 else 'N/A'})\")\n",
    "#                     adata.varm[key] = matrix[:max_genes]\n",
    "    \n",
    "#     print(f\"New shape: {adata.shape}\")\n",
    "#     print(f\"New obsm keys: {list(adata.obsm.keys())}\")\n",
    "    \n",
    "#     # Save truncated file\n",
    "#     print(f\"Saving to {output_path}...\")\n",
    "#     adata.write_h5ad(output_path)\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# # Create mini version of rpe1.h5\n",
    "# rpe1_mini = truncate_adata_file_complete('sample_vcc_data/rpe1.h5', 'sample_vcc_data/rpe1_mini.h5', max_cells=100)\n",
    "# rpe1_mini = truncate_adata_file_complete('sample_vcc_data/hepg2.h5', 'sample_vcc_data/hepg2_mini.h5', max_cells=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
