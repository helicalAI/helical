{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tahoe-x1 Model Tutorial\n",
    "\n",
    "Run this notebook on a colab notebook with a free GPU:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/helicalAI/helical/blob/main/examples/notebooks/Tahoe-x1-Tutorial.ipynb)\n",
    "\n",
    "This tutorial demonstrates how to use the Tahoe-x1 foundation model for single-cell RNA-seq data. Tahoe-x1 is a transformer-based model that can extract both cell and gene embeddings from raw count data.\n",
    "\n",
    "**What you'll learn in this notebook:**\n",
    "- How to load and configure the Tahoe-x1 model\n",
    "- Processing single-cell RNA-seq data for Tahoe\n",
    "- Extracting cell embeddings\n",
    "- Extracting gene embeddings\n",
    "- Visualizing embeddings with UMAP\n",
    "- Extracting attention weights for interpretability\n",
    "\n",
    "For more examples, check out our [GitHub](https://github.com/helicalAI/helical) and [documentation](https://helical.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasched/miniconda3/envs/helical/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Check device availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Load Example Dataset\n",
    "\n",
    "We'll use the human fetal yolk sac scRNA-seq dataset from Helical's Hugging Face repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 25344/25344 [00:14<00:00, 1707.91 examples/s]\n",
      "Generating test split: 100%|██████████| 6336/6336 [00:03<00:00, 2043.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2534 cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\n",
    "    \"helical-ai/yolksac_human\", \n",
    "    split=\"train[:10%]\", \n",
    "    trust_remote_code=True, \n",
    "    download_mode=\"reuse_cache_if_exists\"\n",
    ")\n",
    "\n",
    "# Store labels for visualization later\n",
    "labels = dataset[\"LVL1\"]\n",
    "\n",
    "print(f\"Loaded {len(dataset)} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convert-anndata",
   "metadata": {},
   "source": [
    "## Convert to AnnData Format\n",
    "\n",
    "Tahoe works with AnnData objects, the standard format for single-cell data in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "create-anndata",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 18:21:24,076 - WARNING:py.warnings:/home/rasched/miniconda3/envs/helical/lib/python3.11/functools.py:909: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2534 × 37318\n",
      "    obs: 'LVL1', 'LVL2', 'LVL3'\n",
      "    var: 'gene_name'\n",
      "\n",
      "Using subset: 500 cells, 37318 genes\n"
     ]
    }
   ],
   "source": [
    "from helical.utils import get_anndata_from_hf_dataset\n",
    "\n",
    "ann_data = get_anndata_from_hf_dataset(dataset)\n",
    "print(ann_data)\n",
    "\n",
    "# For this tutorial, let's use a subset for faster processing\n",
    "ann_data_subset = ann_data[:500]  # Use first 500 cells\n",
    "labels_subset = labels[:500]\n",
    "print(f\"\\nUsing subset: {ann_data_subset.n_obs} cells, {ann_data_subset.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-setup",
   "metadata": {},
   "source": [
    "## Initialize Tahoe Model\n",
    "\n",
    "Tahoe comes in three sizes (70m, 1b, 3b). Currently, the 70m model is available. The model uses Flash Attention by default for efficient inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "init-model",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelical\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tahoe, TahoeConfig\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Configure the Tahoe model\u001b[39;00m\n\u001b[32m      4\u001b[39m tahoe_config = TahoeConfig(\n\u001b[32m      5\u001b[39m     model_size=\u001b[33m\"\u001b[39m\u001b[33m70m\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# 12-layer transformer with 512 embedding dimensions\u001b[39;00m\n\u001b[32m      6\u001b[39m     batch_size=\u001b[32m8\u001b[39m,      \u001b[38;5;66;03m# Adjust based on your GPU memory\u001b[39;00m\n\u001b[32m      7\u001b[39m     device=device,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/helical/helical/models/tahoe/__init__.py:17\u001b[39m\n\u001b[32m     14\u001b[39m     handler.setFormatter(formatter)\n\u001b[32m     15\u001b[39m     logger.addHandler(handler)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tahoe\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TahoeConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/helical/helical/models/tahoe/model.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelical\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_gene_symbols_to_ensembl_ids\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelical\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe_x1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TXModel\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelical\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtahoe_x1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loader_from_adata\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/helical/helical/models/tahoe/tahoe_x1/model/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright (C) Tahoe Therapeutics 2025. All rights reserved.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblocks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     ContinuousValueEncoder,\n\u001b[32m      4\u001b[39m     ExprDecoder,\n\u001b[32m      5\u001b[39m     GeneEncoder,\n\u001b[32m      6\u001b[39m     MVCDecoder,\n\u001b[32m      7\u001b[39m     TXBlock,\n\u001b[32m      8\u001b[39m     TXEncoder,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     ComposerTX,\n\u001b[32m     12\u001b[39m     TXModel,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mComposerTX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContinuousValueEncoder\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTXModel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/helical/helical/models/tahoe/tahoe_x1/model/blocks.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attention_classes, norms\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mffn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     resolve_ffn_act_fn,\n\u001b[32m     11\u001b[39m     resolve_ffn_hidden_size,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmpt\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_mpt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_flash_attn_padding_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/llmfoundry/__init__.py:29\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mundefined symbol\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[32m     17\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     18\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mThe flash_attn package is not installed correctly. Usually this means that your runtime version\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     19\u001b[39m             +\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m in LLM Foundry setup.py and update accordingly. The latest Docker image can be found in the README.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     27\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpecificWarningFilter\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Filter out Hugging Face warning for not using a pinned revision of the model\u001b[39;00m\n\u001b[32m     32\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mtransformers.dynamic_module_utils\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/llmfoundry/utils/__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2022 MosaicML LLM Foundry authors\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_transforms\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     add_metrics_to_eval_loaders,\n\u001b[32m      7\u001b[39m     build_algorithm,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     build_tokenizer,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllmfoundry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint_conversion_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     convert_and_save_ft_weights,\n\u001b[32m     22\u001b[39m     get_hf_tokenizer_from_composer_state_dict,\n\u001b[32m     23\u001b[39m     load_tokenizer,\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/llmfoundry/registry.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2024 MosaicML LLM Foundry authors\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# SPDX-License-Identifier: Apache-2.0\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Iterable, Union\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Algorithm, Callback, DataSpec\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggerDestination\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComposerModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/__init__.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"Some key classes are available directly in the ``composer`` namespace.\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Algorithm, Callback, DataSpec, Engine, Evaluator, Event, State, Time, Timestamp, TimeUnit\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloggers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComposerModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/core/__init__.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Algorithm\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callback\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_spec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataSpec, ensure_data_spec\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Engine, Trace\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Evaluator, ensure_evaluator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/core/data_spec.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistributedSampler\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dist, ensure_tuple\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/utils/__init__.py:12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_log_hparams\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     convert_flat_dict_to_nested_dict,\n\u001b[32m      8\u001b[39m     convert_nested_dict_to_flat_dict,\n\u001b[32m      9\u001b[39m     extract_hparams,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m batch_get, batch_set\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     PartialFilePath,\n\u001b[32m     14\u001b[39m     get_save_filename,\n\u001b[32m     15\u001b[39m     load_checkpoint,\n\u001b[32m     16\u001b[39m     safe_torch_load,\n\u001b[32m     17\u001b[39m     save_checkpoint,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollect_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     configure_excepthook,\n\u001b[32m     21\u001b[39m     disable_env_report,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     print_env,\n\u001b[32m     25\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     KNOWN_COMPRESSORS,\n\u001b[32m     28\u001b[39m     CliCompressor,\n\u001b[32m     29\u001b[39m     get_compressor,\n\u001b[32m     30\u001b[39m     is_compressed_pt,\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/utils/checkpoint.py:35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dist, reproducibility\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compressor, is_compressed_pt\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     36\u001b[39m     FORMAT_NAME_WITH_DIST_AND_TIME_TABLE,\n\u001b[32m     37\u001b[39m     extract_path_from_symlink,\n\u001b[32m     38\u001b[39m     format_name_with_dist,\n\u001b[32m     39\u001b[39m     format_name_with_dist_and_time,\n\u001b[32m     40\u001b[39m     get_file,\n\u001b[32m     41\u001b[39m     is_tar,\n\u001b[32m     42\u001b[39m     is_uri,\n\u001b[32m     43\u001b[39m     maybe_create_object_store_from_uri,\n\u001b[32m     44\u001b[39m     parse_uri,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelismType, partial_format\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobject_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ObjectStore\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/utils/file_helpers.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dist\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miter_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterate_with_callback\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partial_format\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobject_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     GCSObjectStore,\n\u001b[32m     26\u001b[39m     LibcloudObjectStore,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     UCObjectStore,\n\u001b[32m     32\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobject_store\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmlflow_object_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLFLOW_DBFS_PATH_PREFIX\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/helical/lib/python3.11/site-packages/composer/utils/misc.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistributedDataParallel\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionDataset\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomposer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_enum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringEnum\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from helical.models.tahoe import Tahoe, TahoeConfig\n",
    "\n",
    "# Configure the Tahoe model\n",
    "tahoe_config = TahoeConfig(\n",
    "    model_size=\"70m\",  # 12-layer transformer with 512 embedding dimensions\n",
    "    batch_size=8,      # Adjust based on your GPU memory\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Initialize the model (will download weights on first use)\n",
    "tahoe = Tahoe(configurer=tahoe_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-data",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "Tahoe requires gene names to be mapped to Ensembl IDs. The `process_data` method handles this automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data - this will map gene symbols to Ensembl IDs\n",
    "dataloader = tahoe.process_data(\n",
    "    ann_data_subset,\n",
    "    gene_names=\"gene_name\",  # Column containing gene symbols\n",
    "    use_raw_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-embeddings-section",
   "metadata": {},
   "source": [
    "## Extract Cell Embeddings\n",
    "\n",
    "Cell embeddings capture the transcriptional state of each cell in a dense vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-cell-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cell embeddings\n",
    "cell_embeddings = tahoe.get_embeddings(dataloader)\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings.shape}\")\n",
    "print(f\"Each cell is represented by a {cell_embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-umap",
   "metadata": {},
   "source": [
    "## Visualize Cell Embeddings with UMAP\n",
    "\n",
    "Let's visualize the cell embeddings in 2D using UMAP to see how cells cluster by cell type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "umap-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce dimensionality with UMAP\n",
    "reducer = umap.UMAP(min_dist=0.1, n_components=2, n_neighbors=15, random_state=42)\n",
    "umap_embedding = reducer.fit_transform(cell_embeddings)\n",
    "\n",
    "# Create plot dataframe\n",
    "plot_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "plot_df['Cell Type'] = labels_subset\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=plot_df, \n",
    "    x='UMAP1', \n",
    "    y='UMAP2', \n",
    "    hue='Cell Type',\n",
    "    palette='tab10',\n",
    "    s=30,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('UMAP Visualization of Tahoe Cell Embeddings', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('UMAP 1', fontsize=12)\n",
    "plt.ylabel('UMAP 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Cell Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-embeddings-section",
   "metadata": {},
   "source": [
    "## Extract Gene Embeddings\n",
    "\n",
    "Tahoe can also extract gene embeddings for each cell. Gene embeddings are returned as a **list of pandas Series** (one per cell), where each Series contains the embeddings for genes expressed in that specific cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-gene-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both cell and gene embeddings\n",
    "cell_embeddings, gene_embeddings = tahoe.get_embeddings(\n",
    "    dataloader,\n",
    "    return_gene_embeddings=True\n",
    ")\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings.shape}\")\n",
    "print(f\"Gene embeddings: {len(gene_embeddings)} cells (list of pandas Series)\")\n",
    "print(f\"\\nFirst cell has {len(gene_embeddings[0])} genes expressed\")\n",
    "\n",
    "# Get first gene embedding from first cell\n",
    "first_gene_embedding = gene_embeddings[0].iloc[0]\n",
    "print(f\"Each gene has a {len(first_gene_embedding)}-dimensional embedding\")\n",
    "\n",
    "print(f\"\\nExample - First 5 genes in first cell:\")\n",
    "for gene_id, embedding in list(gene_embeddings[0].items())[:5]:\n",
    "    print(f\"  {gene_id}: shape {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-viz-section",
   "metadata": {},
   "source": [
    "## Visualize Gene Embeddings\n",
    "\n",
    "Gene embeddings are returned as a list of pandas Series (one per cell), where each Series contains gene embeddings for genes expressed in that cell. Let's aggregate and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-genes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate gene embeddings across all cells (average per gene)\n",
    "from collections import defaultdict\n",
    "\n",
    "gene_embedding_accumulator = defaultdict(lambda: {'sum': None, 'count': 0})\n",
    "\n",
    "# Accumulate embeddings for each gene across all cells\n",
    "for cell_series in gene_embeddings:\n",
    "    for gene_id, embedding in cell_series.items():\n",
    "        if gene_embedding_accumulator[gene_id]['sum'] is None:\n",
    "            gene_embedding_accumulator[gene_id]['sum'] = embedding.copy()\n",
    "        else:\n",
    "            gene_embedding_accumulator[gene_id]['sum'] += embedding\n",
    "        gene_embedding_accumulator[gene_id]['count'] += 1\n",
    "\n",
    "# Average the embeddings\n",
    "aggregated_gene_embeddings = {}\n",
    "for gene_id, data in gene_embedding_accumulator.items():\n",
    "    aggregated_gene_embeddings[gene_id] = data['sum'] / data['count']\n",
    "\n",
    "print(f\"Aggregated gene embeddings for {len(aggregated_gene_embeddings)} unique genes\")\n",
    "\n",
    "# Convert to numpy array for visualization\n",
    "gene_names = list(aggregated_gene_embeddings.keys())\n",
    "gene_embeddings_array = np.stack(list(aggregated_gene_embeddings.values()))\n",
    "\n",
    "print(f\"Embedding shape: {gene_embeddings_array.shape}\")\n",
    "\n",
    "# Visualize a subset of genes with UMAP\n",
    "n_genes_to_plot = min(1000, len(gene_names))\n",
    "gene_subset_idx = np.random.choice(len(gene_names), n_genes_to_plot, replace=False)\n",
    "gene_subset = gene_embeddings_array[gene_subset_idx]\n",
    "\n",
    "# UMAP for genes\n",
    "gene_reducer = umap.UMAP(min_dist=0.1, n_components=2, n_neighbors=15, random_state=42)\n",
    "gene_umap = gene_reducer.fit_transform(gene_subset)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(gene_umap[:, 0], gene_umap[:, 1], s=10, alpha=0.5, c='steelblue')\n",
    "plt.title(f'UMAP Visualization of {n_genes_to_plot} Gene Embeddings', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('UMAP 1', fontsize=12)\n",
    "plt.ylabel('UMAP 2', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nYou can access gene embeddings for a specific cell:\")\n",
    "print(f\"Example: gene_embeddings[0]['{gene_names[0]}']  # First cell, specific gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attention-section",
   "metadata": {},
   "source": [
    "## Extract Attention Weights\n",
    "\n",
    "For interpretability, you can extract attention weights from the transformer layers. This requires using the PyTorch attention implementation instead of Flash Attention.\n",
    "\n",
    "**Note:** This is slower and uses more memory than the default Flash Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attention-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with torch attention implementation\n",
    "tahoe_config_attn = TahoeConfig(\n",
    "    model_size=\"70m\",\n",
    "    batch_size=4,  # Reduce batch size for memory efficiency\n",
    "    device=device,\n",
    "    attn_impl='torch'  # Required for attention extraction\n",
    ")\n",
    "\n",
    "tahoe_attn = Tahoe(configurer=tahoe_config_attn)\n",
    "print(\"Tahoe model with attention extraction loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-for-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a smaller subset for attention extraction\n",
    "ann_data_tiny = ann_data[:50]  # Use only 50 cells\n",
    "\n",
    "dataloader_attn = tahoe_attn.process_data(\n",
    "    ann_data_tiny,\n",
    "    gene_names=\"gene_name\",\n",
    "    use_raw_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention weights\n",
    "cell_embeddings_attn, attention_weights = tahoe_attn.get_embeddings(\n",
    "    dataloader_attn, \n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings_attn.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "print(f\"\\nAttention weights dimensions: (n_cells, n_heads, seq_length, seq_length)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-attention-section",
   "metadata": {},
   "source": [
    "## Visualize Attention Patterns\n",
    "\n",
    "Let's visualize the attention pattern for one cell to see which genes the model pays attention to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first cell and average across attention heads\n",
    "cell_idx = 0\n",
    "cell_attention = attention_weights[cell_idx]  # Shape: (n_heads, seq_len, seq_len)\n",
    "\n",
    "# Average across heads\n",
    "avg_attention = cell_attention.mean(axis=0)  # Shape: (seq_len, seq_len)\n",
    "\n",
    "# Find actual sequence length (excluding padding)\n",
    "non_zero_mask = avg_attention.sum(axis=1) > 0\n",
    "actual_seq_len = non_zero_mask.sum()\n",
    "avg_attention_trimmed = avg_attention[:actual_seq_len, :actual_seq_len]\n",
    "\n",
    "# Plot attention heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    avg_attention_trimmed[:50, :50],  # Show first 50x50 for visibility\n",
    "    cmap='viridis',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Attention Weight'}\n",
    ")\n",
    "plt.title(f'Attention Pattern for Cell {cell_idx} (averaged across heads)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Key Position (Gene Tokens)', fontsize=12)\n",
    "plt.ylabel('Query Position (Gene Tokens)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Showing first 50x50 positions of {actual_seq_len} total sequence length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s7bwwq6axah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transformer embeddings with their corresponding gene IDs\n",
    "# This ensures we know which embedding corresponds to which gene\n",
    "transformer_embs, gene_ids = tahoe.get_transformer_embeddings(dataloader)\n",
    "\n",
    "print(f\"Number of cells: {len(transformer_embs)}\")\n",
    "print(f\"First cell embeddings shape: {transformer_embs[0].shape}\")\n",
    "print(f\"First cell gene IDs shape: {gene_ids[0].shape}\")\n",
    "print(f\"Embedding dimension: {transformer_embs[0].shape[1]}\")\n",
    "\n",
    "# Show the gene mapping for first cell\n",
    "pad_token_id = tahoe.collator_cfg[\"pad_token_id\"]\n",
    "idx_to_gene = tahoe.vocab.index_to_token\n",
    "\n",
    "print(f\"\\nFirst cell - first 5 non-padding genes:\")\n",
    "count = 0\n",
    "for pos in range(len(gene_ids[0])):\n",
    "    if gene_ids[0][pos] != pad_token_id and count < 5:\n",
    "        gene_name = idx_to_gene[gene_ids[0][pos]]\n",
    "        print(f\"  Position {pos}: {gene_name} (ID: {gene_ids[0][pos]})\")\n",
    "        count += 1\n",
    "\n",
    "# Optional: Modify embeddings for perturbation experiments\n",
    "# Example - perturb gene at position 5 in first cell\n",
    "# transformer_embs[0][5, :] += np.random.randn(transformer_embs[0].shape[1]) * 0.1\n",
    "\n",
    "# Decode embeddings to predicted expression\n",
    "# Returns a list of pandas Series (one per cell)\n",
    "expr_predictions = tahoe.decode_embeddings(transformer_embs, gene_ids)\n",
    "\n",
    "print(f\"\\nNumber of cells with predictions: {len(expr_predictions)}\")\n",
    "print(f\"First cell has predictions for {len(expr_predictions[0])} genes\")\n",
    "\n",
    "# Show predictions for first cell, first 5 genes\n",
    "print(f\"\\nFirst cell - predicted expression for first 5 genes:\")\n",
    "for gene_name, pred_expr in list(expr_predictions[0].items())[:5]:\n",
    "    print(f\"  {gene_name}: {pred_expr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9rl846l5ph9",
   "metadata": {},
   "source": [
    "## Expression Prediction with Decoder\n",
    "\n",
    "Tahoe includes an expression decoder that can predict gene expression values from embeddings. This is useful for:\n",
    "- **In-silico perturbation**: Modify gene embeddings and predict resulting expression changes\n",
    "- **Counterfactual analysis**: Answer \"what if\" questions about gene regulation\n",
    "- **Expression imputation**: Predict expression from partial or modified embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tauvtjy6cz8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ✅ Load and configure the Tahoe-x1 model for single-cell RNA-seq analysis\n",
    "2. ✅ Process scRNA-seq data with automatic gene symbol to Ensembl ID mapping\n",
    "3. ✅ Extract cell embeddings that capture cellular states\n",
    "4. ✅ Extract gene embeddings per cell (list of pandas Series, one per cell)\n",
    "5. ✅ Visualize embeddings using UMAP for exploratory analysis\n",
    "6. ✅ Extract and visualize attention weights for model interpretability\n",
    "7. ✅ Use the expression decoder for predicting expression from embeddings\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Cell embeddings**: Dense vector representations capturing cellular transcriptional states (numpy array)\n",
    "- **Gene embeddings**: List of pandas Series, one per cell. Each Series contains gene embeddings indexed by Ensembl IDs for genes expressed in that cell\n",
    "- **Attention weights**: Interpretable attention patterns (requires `attn_impl='torch'`)\n",
    "- **Expression decoder**: Predict gene expression values from embeddings (useful for perturbation experiments)\n",
    "\n",
    "### Gene Embeddings Structure\n",
    "\n",
    "```python\n",
    "# gene_embeddings is a list with length = number of cells\n",
    "len(gene_embeddings)  # e.g., 500 cells\n",
    "\n",
    "# Each element is a pandas Series for that cell\n",
    "gene_embeddings[0]  # pandas Series with gene IDs as keys\n",
    "\n",
    "# Access specific gene in specific cell\n",
    "gene_embeddings[0]['ENSG00000123456']  # numpy array of shape (embedding_dim,)\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Cell Type Annotation**: Use the embeddings for downstream tasks like cell type classification\n",
    "- **Gene Analysis**: Analyze gene expression patterns using per-cell gene embeddings\n",
    "- **Perturbation Experiments**: Use the decoder to predict expression changes from modified embeddings\n",
    "- **Integration**: Combine Tahoe embeddings with other analysis tools in the scRNA-seq ecosystem\n",
    "- **Fine-tuning**: Adapt the model for specific downstream tasks (see other notebooks)\n",
    "\n",
    "### Model Information\n",
    "\n",
    "- **Model**: Tahoe-x1 by Tahoe Therapeutics\n",
    "- **Hugging Face**: [tahoebio/Tahoe-x1](https://huggingface.co/tahoebio/Tahoe-x1)\n",
    "- **Architecture**: Transformer-based foundation model for scRNA-seq\n",
    "- **Available sizes**: 70m (12 layers, 512d), 1b (24 layers, 1024d), 3b (36 layers, 1536d)\n",
    "\n",
    "For more information and examples, visit the [Helical documentation](https://helical.readthedocs.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
