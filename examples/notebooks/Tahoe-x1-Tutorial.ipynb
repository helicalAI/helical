{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Tahoe-x1 Model Tutorial\n",
    "\n",
    "Run this notebook on a colab notebook with a free GPU:\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/helicalAI/helical/blob/main/examples/notebooks/Tahoe-x1-Tutorial.ipynb)\n",
    "\n",
    "This tutorial demonstrates how to use the Tahoe-x1 foundation model for single-cell RNA-seq data. Tahoe-x1 is a transformer-based model that can extract both cell and gene embeddings from raw count data.\n",
    "\n",
    "**What you'll learn in this notebook:**\n",
    "- How to load and configure the Tahoe-x1 model\n",
    "- Processing single-cell RNA-seq data for Tahoe\n",
    "- Extracting cell embeddings\n",
    "- Extracting gene embeddings\n",
    "- Visualizing embeddings with UMAP\n",
    "- Extracting attention weights for interpretability\n",
    "\n",
    "For more examples, check out our [GitHub](https://github.com/helicalAI/helical) and [documentation](https://helical.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install or update Helical to get access to the Tahoe model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-helical",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install helical --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Configure logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check device availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Load Example Dataset\n",
    "\n",
    "We'll use the human fetal yolk sac scRNA-seq dataset from Helical's Hugging Face repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\n",
    "    \"helical-ai/yolksac_human\", \n",
    "    split=\"train[:10%]\", \n",
    "    trust_remote_code=True, \n",
    "    download_mode=\"reuse_cache_if_exists\"\n",
    ")\n",
    "\n",
    "# Store labels for visualization later\n",
    "labels = dataset[\"LVL1\"]\n",
    "\n",
    "print(f\"Loaded {len(dataset)} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convert-anndata",
   "metadata": {},
   "source": [
    "## Convert to AnnData Format\n",
    "\n",
    "Tahoe works with AnnData objects, the standard format for single-cell data in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-anndata",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.utils import get_anndata_from_hf_dataset\n",
    "\n",
    "ann_data = get_anndata_from_hf_dataset(dataset)\n",
    "print(ann_data)\n",
    "\n",
    "# For this tutorial, let's use a subset for faster processing\n",
    "ann_data_subset = ann_data[:500]  # Use first 500 cells\n",
    "labels_subset = labels[:500]\n",
    "print(f\"\\nUsing subset: {ann_data_subset.n_obs} cells, {ann_data_subset.n_vars} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-setup",
   "metadata": {},
   "source": [
    "## Initialize Tahoe Model\n",
    "\n",
    "Tahoe comes in three sizes (70m, 1b, 3b). Currently, the 70m model is available. The model uses Flash Attention by default for efficient inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.tahoe import Tahoe, TahoeConfig\n",
    "\n",
    "# Configure the Tahoe model\n",
    "tahoe_config = TahoeConfig(\n",
    "    model_size=\"70m\",  # 12-layer transformer with 512 embedding dimensions\n",
    "    batch_size=8,      # Adjust based on your GPU memory\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Initialize the model (will download weights on first use)\n",
    "tahoe = Tahoe(configurer=tahoe_config)\n",
    "\n",
    "print(\"\\nTahoe model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-data",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "Tahoe requires gene names to be mapped to Ensembl IDs. The `process_data` method handles this automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data - this will map gene symbols to Ensembl IDs\n",
    "dataloader = tahoe.process_data(\n",
    "    ann_data_subset,\n",
    "    gene_names=\"gene_name\",  # Column containing gene symbols\n",
    "    use_raw_counts=True\n",
    ")\n",
    "\n",
    "print(\"Data processed and ready for inference!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-embeddings-section",
   "metadata": {},
   "source": [
    "## Extract Cell Embeddings\n",
    "\n",
    "Cell embeddings capture the transcriptional state of each cell in a dense vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-cell-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cell embeddings\n",
    "cell_embeddings = tahoe.get_embeddings(dataloader)\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings.shape}\")\n",
    "print(f\"Each cell is represented by a {cell_embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-umap",
   "metadata": {},
   "source": [
    "## Visualize Cell Embeddings with UMAP\n",
    "\n",
    "Let's visualize the cell embeddings in 2D using UMAP to see how cells cluster by cell type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "umap-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce dimensionality with UMAP\n",
    "reducer = umap.UMAP(min_dist=0.1, n_components=2, n_neighbors=15, random_state=42)\n",
    "umap_embedding = reducer.fit_transform(cell_embeddings)\n",
    "\n",
    "# Create plot dataframe\n",
    "plot_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "plot_df['Cell Type'] = labels_subset\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=plot_df, \n",
    "    x='UMAP1', \n",
    "    y='UMAP2', \n",
    "    hue='Cell Type',\n",
    "    palette='tab10',\n",
    "    s=30,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('UMAP Visualization of Tahoe Cell Embeddings', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('UMAP 1', fontsize=12)\n",
    "plt.ylabel('UMAP 2', fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Cell Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-embeddings-section",
   "metadata": {},
   "source": [
    "## Extract Gene Embeddings\n",
    "\n",
    "Tahoe can also extract gene embeddings, which represent how each gene is expressed across all cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-gene-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get both cell and gene embeddings\n",
    "cell_embeddings, gene_embeddings = tahoe.get_embeddings(\n",
    "    dataloader, \n",
    "    return_gene_embeddings=True\n",
    ")\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings.shape}\")\n",
    "print(f\"Gene embeddings shape: {gene_embeddings.shape}\")\n",
    "print(f\"\\nEach gene is represented by a {gene_embeddings.shape[1]}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gene-viz-section",
   "metadata": {},
   "source": [
    "## Visualize Gene Embeddings\n",
    "\n",
    "Let's visualize a subset of gene embeddings to see how genes cluster based on their expression patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-genes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove genes with NaN embeddings (genes not present in the data)\n",
    "valid_genes = ~np.isnan(gene_embeddings).any(axis=1)\n",
    "gene_embeddings_valid = gene_embeddings[valid_genes]\n",
    "\n",
    "print(f\"Valid gene embeddings: {gene_embeddings_valid.shape[0]} genes\")\n",
    "\n",
    "# Visualize a subset of genes with UMAP\n",
    "n_genes_to_plot = min(1000, gene_embeddings_valid.shape[0])\n",
    "gene_subset_idx = np.random.choice(gene_embeddings_valid.shape[0], n_genes_to_plot, replace=False)\n",
    "gene_subset = gene_embeddings_valid[gene_subset_idx]\n",
    "\n",
    "# UMAP for genes\n",
    "gene_reducer = umap.UMAP(min_dist=0.1, n_components=2, n_neighbors=15, random_state=42)\n",
    "gene_umap = gene_reducer.fit_transform(gene_subset)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(gene_umap[:, 0], gene_umap[:, 1], s=10, alpha=0.5, c='steelblue')\n",
    "plt.title(f'UMAP Visualization of {n_genes_to_plot} Gene Embeddings', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('UMAP 1', fontsize=12)\n",
    "plt.ylabel('UMAP 2', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attention-section",
   "metadata": {},
   "source": [
    "## Extract Attention Weights\n",
    "\n",
    "For interpretability, you can extract attention weights from the transformer layers. This requires using the PyTorch attention implementation instead of Flash Attention.\n",
    "\n",
    "**Note:** This is slower and uses more memory than the default Flash Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attention-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with torch attention implementation\n",
    "tahoe_config_attn = TahoeConfig(\n",
    "    model_size=\"70m\",\n",
    "    batch_size=4,  # Reduce batch size for memory efficiency\n",
    "    device=device,\n",
    "    attn_impl='torch'  # Required for attention extraction\n",
    ")\n",
    "\n",
    "tahoe_attn = Tahoe(configurer=tahoe_config_attn)\n",
    "print(\"Tahoe model with attention extraction loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-for-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a smaller subset for attention extraction\n",
    "ann_data_tiny = ann_data[:50]  # Use only 50 cells\n",
    "\n",
    "dataloader_attn = tahoe_attn.process_data(\n",
    "    ann_data_tiny,\n",
    "    gene_names=\"gene_name\",\n",
    "    use_raw_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention weights\n",
    "cell_embeddings_attn, attention_weights = tahoe_attn.get_embeddings(\n",
    "    dataloader_attn, \n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "print(f\"Cell embeddings shape: {cell_embeddings_attn.shape}\")\n",
    "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
    "print(f\"\\nAttention weights dimensions: (n_cells, n_heads, seq_length, seq_length)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-attention-section",
   "metadata": {},
   "source": [
    "## Visualize Attention Patterns\n",
    "\n",
    "Let's visualize the attention pattern for one cell to see which genes the model pays attention to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first cell and average across attention heads\n",
    "cell_idx = 0\n",
    "cell_attention = attention_weights[cell_idx]  # Shape: (n_heads, seq_len, seq_len)\n",
    "\n",
    "# Average across heads\n",
    "avg_attention = cell_attention.mean(axis=0)  # Shape: (seq_len, seq_len)\n",
    "\n",
    "# Find actual sequence length (excluding padding)\n",
    "non_zero_mask = avg_attention.sum(axis=1) > 0\n",
    "actual_seq_len = non_zero_mask.sum()\n",
    "avg_attention_trimmed = avg_attention[:actual_seq_len, :actual_seq_len]\n",
    "\n",
    "# Plot attention heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    avg_attention_trimmed[:50, :50],  # Show first 50x50 for visibility\n",
    "    cmap='viridis',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Attention Weight'}\n",
    ")\n",
    "plt.title(f'Attention Pattern for Cell {cell_idx} (averaged across heads)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Key Position (Gene Tokens)', fontsize=12)\n",
    "plt.ylabel('Query Position (Gene Tokens)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Showing first 50x50 positions of {actual_seq_len} total sequence length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "1. ✅ Load and configure the Tahoe-x1 model for single-cell RNA-seq analysis\n",
    "2. ✅ Process scRNA-seq data with automatic gene symbol to Ensembl ID mapping\n",
    "3. ✅ Extract cell embeddings that capture cellular states\n",
    "4. ✅ Extract gene embeddings that represent gene expression patterns\n",
    "5. ✅ Visualize embeddings using UMAP for exploratory analysis\n",
    "6. ✅ Extract and visualize attention weights for model interpretability\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Cell Type Annotation**: Use the embeddings for downstream tasks like cell type classification\n",
    "- **Gene Analysis**: Identify gene modules or marker genes using gene embeddings\n",
    "- **Integration**: Combine Tahoe embeddings with other analysis tools in the scRNA-seq ecosystem\n",
    "- **Fine-tuning**: Adapt the model for specific downstream tasks (see other notebooks)\n",
    "\n",
    "### Model Information\n",
    "\n",
    "- **Model**: Tahoe-x1 by Tahoe Therapeutics\n",
    "- **Hugging Face**: [tahoebio/Tahoe-x1](https://huggingface.co/tahoebio/Tahoe-x1)\n",
    "- **Architecture**: Transformer-based foundation model for scRNA-seq\n",
    "- **Available sizes**: 70m (12 layers, 512d), 1b (24 layers, 1024d), 3b (36 layers, 1536d)\n",
    "\n",
    "For more information and examples, visit the [Helical documentation](https://helical.readthedocs.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
