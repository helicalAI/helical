{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f5b3bc",
   "metadata": {},
   "source": [
    "This notebook goes over how to use `STATE` using `helical`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cbea7",
   "metadata": {},
   "source": [
    "# Download Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40e1b8",
   "metadata": {},
   "source": [
    "We start by using the helical downloader to obtain an example huggingface dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed699842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "from pathlib import Path\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_link(\n",
    "    Path(\"yolksac_human.h5ad\"),\n",
    "    \"https://huggingface.co/datasets/helical-ai/yolksac_human/resolve/main/data/17_04_24_YolkSacRaw_F158_WE_annots.h5ad?download=true\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e8491",
   "metadata": {},
   "source": [
    "# STATE Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ed3a3",
   "metadata": {},
   "source": [
    "Using the STATE model we can obtain single cell transcriptome embeddings. We first slice the dataset for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"yolksac_human.h5ad\")\n",
    "# for demonstration we subset to 10 cells and 2000 genes\n",
    "adata = adata[:10, :2000].copy()\n",
    "\n",
    "print(adata.shape)\n",
    "n_cells = adata.n_obs\n",
    "print(n_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1c1b5",
   "metadata": {},
   "source": [
    "Initialise the model - this will download the relevant files needed in `.cache/helical/state/`. It will download the necessary files when run the first time so will take slightly longer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e73cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateConfig\n",
    "from helical.models.state import stateEmbed\n",
    "\n",
    "state_config = stateConfig(batch_size=16)\n",
    "state_embed = stateEmbed(configurer=state_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b4c72",
   "metadata": {},
   "source": [
    "We process the data by calling `state_embed.process_data` and pass this into `state_embed.get_embeddings` to get the final embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = state_embed.process_data(adata=adata)\n",
    "embeddings = state_embed.get_embeddings(processed_data)\n",
    "\n",
    "# note that the STATE model returns a numpy array of shape (n_cells, 1024)\n",
    "print(embeddings.shape)\n",
    "print(type(embeddings))\n",
    "\n",
    "# store the embeddings in adata.obsm['state_emb']\n",
    "adata.obsm['state_emb'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861511f",
   "metadata": {},
   "source": [
    "# STATE Perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43c1bb",
   "metadata": {},
   "source": [
    "To use the perturbation model you can either pass in embeddings by specifiyng the `embed_key` arguement in `stateConfig` or use the deafult `None` value in which case the expression values are used (`adata.X`).\n",
    "\n",
    "For use of previous embeddings, the `embed_key` must exist in `adata.obsm[<embed_key>]` otherwise an error will be thrown. When set to `None` the model uses `adata.X`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6cd96",
   "metadata": {},
   "source": [
    "Let's create some dummy data for the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# some default control and non-control perturbations\n",
    "perturbations = [\n",
    "    \"[('DMSO_TF', 0.0, 'uM')]\",  # Control\n",
    "    \"[('Aspirin', 0.5, 'uM')]\",\n",
    "    \"[('Dexamethasone', 1.0, 'uM')]\",\n",
    "]\n",
    "\n",
    "n_cells = adata.n_obs\n",
    "# we assign perturbations to cells randomly\n",
    "adata.obs['target_gene'] = np.random.choice(perturbations, size=n_cells)\n",
    "adata.obs['cell_type'] = adata.obs['LVL1']  # Use your cell type column\n",
    "# we can also add a batch variable to take into account batch effects\n",
    "batch_labels = np.random.choice(['batch_1', 'batch_2', 'batch_3', 'batch_4'], size=n_cells)\n",
    "adata.obs['batch_var'] = batch_labels\n",
    "\n",
    "config = stateConfig(\n",
    "    embed_key='state_emb', # our custom embedding key from above\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    output_path=\"yolksac_perturbed.h5ad\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c11cfb",
   "metadata": {},
   "source": [
    "Now we can run the perturbation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab93647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateTransitionModel\n",
    "\n",
    "state_transition = stateTransitionModel(configurer=config)\n",
    "\n",
    "# again we process the data and get the perturbed embeddings\n",
    "processed_data = state_transition.process_data(adata)\n",
    "perturbed_embeds = state_transition.get_embeddings(processed_data)\n",
    "\n",
    "print(perturbed_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582345dd",
   "metadata": {},
   "source": [
    "# Finetuning STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e835b83",
   "metadata": {},
   "source": [
    "We can finetune the STATE perturbation embeddings using an additional head for downstream classification and regression. Below is a dummy example using data above to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateFineTuningModel\n",
    "\n",
    "# Dummy cell types and labels for demonstration\n",
    "cell_types = list(adata.obs['LVL1'])\n",
    "label_set = set(cell_types)\n",
    "print(f\"Found {len(label_set)} unique cell types:\")\n",
    "\n",
    "config = stateConfig(\n",
    "    embed_key=\"state_emb\",  # Use gene expression instead of embeddings\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "# Create the fine-tuning model - we use a classification head for demonstration\n",
    "model = stateFineTuningModel(\n",
    "    configurer=config, \n",
    "    fine_tuning_head=\"classification\", \n",
    "    output_size=len(label_set),\n",
    ")\n",
    "\n",
    "# Process the data for training - returns a dataset object\n",
    "data = model.process_data(adata)\n",
    "\n",
    "# Create a dictionary mapping the classes to unique integers for training\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "# Convert cell type labels to integers\n",
    "cell_type_labels = [class_id_dict[ct] for ct in cell_types]\n",
    "\n",
    "print(f\"Class mapping: {class_id_dict}\")\n",
    "\n",
    "# Fine-tune\n",
    "model.train(train_input_data=data, train_labels=cell_type_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53936df",
   "metadata": {},
   "source": [
    "# Training STATE for the Virtual Cell Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be814ae",
   "metadata": {},
   "source": [
    "We use data from the Virtual Cell Challenge for model training and downstream inference. For this we require the VCC dataset as in the colab notebook by the authors. See the relevant code snippet for the entire dataset in the below colab notebook:\n",
    "\n",
    "[STATE Colab Notebook](https://colab.research.google.com/drive/1QKOtYP7bMpdgDJEipDxaJqOchv7oQ-_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e7ad8",
   "metadata": {},
   "source": [
    "For demonstration we use a subset of the data. We also need to change the filepath in `starter.toml` to point to the correct dataset location (see top of file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "import toml\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_name(\"sample_vcc_data\")\n",
    "\n",
    "# quick one-liner to change the filepath in starter.toml to point to correct path\n",
    "toml.dump({**toml.load(open(\"sample_vcc_data/starter.toml\")),**{\"datasets\": {\"replogle_h1\": str(Path(\"sample_vcc_data\").absolute() / \"{rpe1,hepg2}.h5\")}},},open(\"sample_vcc_data/starter.toml\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974174ac",
   "metadata": {},
   "source": [
    "We use the `stateTransitionTrainModel` class and initialise training configurations using the `config.yaml` file in the sample directory. You can edit these based on your training preferences. Currently this is set to one epoch for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23307fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then train the model and perform inference on a held out test set\n",
    "from helical.models.state import stateTransitionTrainModel\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "model_configs = OmegaConf.load(\"sample_vcc_data/config.yaml\")\n",
    "state_train = stateTransitionTrainModel(configurer=model_configs)\n",
    "state_train.train() \n",
    "state_train.predict() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb512a0",
   "metadata": {},
   "source": [
    "The trained model will be saved to the `sample_vcc_data/first_run` directory, alongside the necessary files and checkpoints to intialise a new model. We can initialise `stateTransitionModel` as before and run inference. For consistency with the `stateConfig` copy the `config.yaml` to the directory set as `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be67236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateTransitionModel\n",
    "from helical.models.state import stateConfig\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"sample_vcc_data/test.h5ad\")\n",
    "\n",
    "state_config = stateConfig(\n",
    "    output_path = \"mini_run/prediction.h5ad\",\n",
    "    perturb_dir = \"mini_run/first_run\",\n",
    "    pert_col = \"target_gene\",\n",
    ")\n",
    "\n",
    "state_transition = stateTransitionModel(configurer=state_config)\n",
    "processed_data = state_transition.process_data(adata)\n",
    "embeds = state_transition.get_embeddings(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45529597",
   "metadata": {},
   "source": [
    "Now you can use the `cell-eval` package to create a submission to the Virtual Cell Challenge (generates a `.vcc` file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a629a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cell-eval\n",
    "! cell-eval prep -i mini_run/prediction.h5ad -g sample_vcc_data/gene_names.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3902e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scanpy as sc\n",
    "# import numpy as np\n",
    "\n",
    "# def create_balanced_mini_dataset(input_path, output_path, n_cells=100):\n",
    "#     \"\"\"\n",
    "#     Create a mini dataset that preserves both control and perturbation cells\n",
    "#     \"\"\"\n",
    "#     adata = sc.read_h5ad(input_path)\n",
    "    \n",
    "#     # Find control and perturbation cells\n",
    "#     control_mask = adata.obs['target_gene'] == 'non-targeting'\n",
    "#     pert_mask = ~control_mask\n",
    "    \n",
    "#     control_indices = np.where(control_mask)[0]\n",
    "#     pert_indices = np.where(pert_mask)[0]\n",
    "    \n",
    "#     print(f\"Original: {len(control_indices)} control, {len(pert_indices)} perturbation cells\")\n",
    "    \n",
    "#     # Sample proportionally\n",
    "#     n_control = min(n_cells // 2, len(control_indices))\n",
    "#     n_pert = min(n_cells - n_control, len(pert_indices))\n",
    "    \n",
    "#     # If we need more cells, fill with the remaining type\n",
    "#     if n_control + n_pert < n_cells:\n",
    "#         if len(control_indices) > n_control:\n",
    "#             n_control = min(n_cells, len(control_indices))\n",
    "#             n_pert = 0\n",
    "#         elif len(pert_indices) > n_pert:\n",
    "#             n_pert = min(n_cells, len(pert_indices))\n",
    "#             n_control = 0\n",
    "    \n",
    "#     # Sample indices\n",
    "#     np.random.seed(42)\n",
    "#     sampled_control = np.random.choice(control_indices, size=n_control, replace=False) if n_control > 0 else np.array([])\n",
    "#     sampled_pert = np.random.choice(pert_indices, size=n_pert, replace=False) if n_pert > 0 else np.array([])\n",
    "    \n",
    "#     # Combine and create new dataset\n",
    "#     all_sampled = np.concatenate([sampled_control, sampled_pert])\n",
    "#     adata_mini = adata[all_sampled, :].copy()\n",
    "    \n",
    "#     print(f\"Mini dataset: {len(sampled_control)} control, {len(sampled_pert)} perturbation cells\")\n",
    "#     print(f\"Total: {adata_mini.shape}\")\n",
    "    \n",
    "#     adata_mini.write_h5ad(output_path)\n",
    "#     return adata_mini\n",
    "\n",
    "# # Create a balanced mini dataset\n",
    "# mini_val = create_balanced_mini_dataset(\"competition_support_set/competition_val_template.h5ad\", \"competition_support_set/mini_val_balanced.h5ad\", n_cells=100)\n",
    "\n",
    "# import scanpy as sc\n",
    "# import anndata as ad\n",
    "\n",
    "# def truncate_adata_file_complete(input_path, output_path, max_cells=100, max_genes=None):\n",
    "#     \"\"\"\n",
    "#     Truncate an AnnData file and handle ALL fields properly\n",
    "#     \"\"\"\n",
    "#     print(f\"Loading {input_path}...\")\n",
    "#     adata = sc.read_h5ad(input_path)\n",
    "    \n",
    "#     print(f\"Original shape: {adata.shape}\")\n",
    "#     print(f\"Original obsm keys: {list(adata.obsm.keys())}\")\n",
    "    \n",
    "#     # Truncate cells\n",
    "#     if max_cells and adata.n_obs > max_cells:\n",
    "#         print(f\"Truncating to {max_cells} cells...\")\n",
    "        \n",
    "#         # Truncate main data\n",
    "#         adata = adata[:max_cells, :].copy()\n",
    "        \n",
    "#         # Manually truncate obsm fields that might not be handled properly\n",
    "#         for key in adata.obsm.keys():\n",
    "#             matrix = adata.obsm[key]\n",
    "#             if hasattr(matrix, 'shape') and len(matrix.shape) > 0:\n",
    "#                 if matrix.shape[0] > max_cells:\n",
    "#                     print(f\"Truncating obsm['{key}'] from {matrix.shape} to ({max_cells}, {matrix.shape[1] if len(matrix.shape) > 1 else 'N/A'})\")\n",
    "#                     adata.obsm[key] = matrix[:max_cells]\n",
    "    \n",
    "#     # Truncate genes (optional)\n",
    "#     if max_genes and adata.n_vars > max_genes:\n",
    "#         print(f\"Truncating to {max_genes} genes...\")\n",
    "        \n",
    "#         # Truncate main data\n",
    "#         adata = adata[:, :max_genes].copy()\n",
    "        \n",
    "#         # Manually truncate varm fields\n",
    "#         for key in adata.varm.keys():\n",
    "#             matrix = adata.varm[key]\n",
    "#             if hasattr(matrix, 'shape') and len(matrix.shape) > 0:\n",
    "#                 if matrix.shape[0] > max_genes:\n",
    "#                     print(f\"Truncating varm['{key}'] from {matrix.shape} to ({max_genes}, {matrix.shape[1] if len(matrix.shape) > 1 else 'N/A'})\")\n",
    "#                     adata.varm[key] = matrix[:max_genes]\n",
    "    \n",
    "#     print(f\"New shape: {adata.shape}\")\n",
    "#     print(f\"New obsm keys: {list(adata.obsm.keys())}\")\n",
    "    \n",
    "#     # Save truncated file\n",
    "#     print(f\"Saving to {output_path}...\")\n",
    "#     adata.write_h5ad(output_path)\n",
    "    \n",
    "#     return adata\n",
    "\n",
    "# # Create mini version of rpe1.h5\n",
    "# rpe1_mini = truncate_adata_file_complete('sample_vcc_data/rpe1.h5', 'sample_vcc_data/rpe1_mini.h5', max_cells=100)\n",
    "# rpe1_mini = truncate_adata_file_complete('sample_vcc_data/hepg2.h5', 'sample_vcc_data/hepg2_mini.h5', max_cells=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
