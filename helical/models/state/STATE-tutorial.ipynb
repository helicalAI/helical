{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f5b3bc",
   "metadata": {},
   "source": [
    "This notebook goes over how to use `STATE` using `helical`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cbea7",
   "metadata": {},
   "source": [
    "# Download Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40e1b8",
   "metadata": {},
   "source": [
    "We start by using the helical downloader to obtain an example huggingface dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed699842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "from pathlib import Path\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_link(\n",
    "    Path(\"yolksac_human.h5ad\"),\n",
    "    \"https://huggingface.co/datasets/helical-ai/yolksac_human/resolve/main/data/17_04_24_YolkSacRaw_F158_WE_annots.h5ad?download=true\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484e8491",
   "metadata": {},
   "source": [
    "# STATE Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ed3a3",
   "metadata": {},
   "source": [
    "Using the STATE model we can obtain single cell transcriptome embeddings. We first slice the dataset for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data \n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.read_h5ad(\"yolksac_human.h5ad\")\n",
    "# for demonstration we subset to 10 cells and 2000 genes\n",
    "adata = adata[:10, :2000].copy()\n",
    "\n",
    "print(adata.shape)\n",
    "n_cells = adata.n_obs\n",
    "print(n_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1c1b5",
   "metadata": {},
   "source": [
    "Initialise the model - this will download the relevant files needed in `.cache/helical/state/`. It will download the necessary files when run the first time so will take slightly longer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e73cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helical.models.state.state_embeddings:Using model checkpoint: /home/rasched/.cache/helical/models/state/state_embed/se600m_model_weights.pt\n",
      "INFO:helical.models.state.state_embeddings:Successfully loaded model\n"
     ]
    }
   ],
   "source": [
    "from helical.models.state import stateConfig\n",
    "from helical.models.state import stateEmbed\n",
    "\n",
    "state_config = stateConfig(batch_size=16)\n",
    "state_embed = stateEmbed(configurer=state_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b4c72",
   "metadata": {},
   "source": [
    "We process the data by calling `state_embed.process_data` and pass this into `state_embed.get_embeddings` to get the final embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = state_embed.process_data(adata=adata)\n",
    "embeddings = state_embed.get_embeddings(processed_data)\n",
    "\n",
    "# note that the STATE model returns a numpy array of shape (n_cells, 1024)\n",
    "print(embeddings.shape)\n",
    "print(type(embeddings))\n",
    "\n",
    "# store the embeddings in adata.obsm['state_emb']\n",
    "adata.obsm['state_emb'] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861511f",
   "metadata": {},
   "source": [
    "# STATE Perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43c1bb",
   "metadata": {},
   "source": [
    "To use the perturbation model you can either pass in embeddings by specifiyng the `embed_key` arguement in `stateConfig` or use the deafult `None` value in which case the expression values are used (`adata.X`).\n",
    "\n",
    "For use of previous embeddings, the `embed_key` must exist in `adata.obsm[<embed_key>]` otherwise an error will be thrown. When set to `None` the model uses `adata.X`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c6cd96",
   "metadata": {},
   "source": [
    "Let's create some dummy data for the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abafa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# some default control and non-control perturbations\n",
    "perturbations = [\n",
    "    \"[('DMSO_TF', 0.0, 'uM')]\",  # Control\n",
    "    \"[('Aspirin', 0.5, 'uM')]\",\n",
    "    \"[('Dexamethasone', 1.0, 'uM')]\",\n",
    "]\n",
    "\n",
    "n_cells = adata.n_obs\n",
    "# we assign perturbations to cells randomly\n",
    "adata.obs['target_gene'] = np.random.choice(perturbations, size=n_cells)\n",
    "adata.obs['cell_type'] = adata.obs['LVL1']  # Use your cell type column\n",
    "# we can also add a batch variable to take into account batch effects\n",
    "batch_labels = np.random.choice(['batch_1', 'batch_2', 'batch_3', 'batch_4'], size=n_cells)\n",
    "adata.obs['batch_var'] = batch_labels\n",
    "\n",
    "config = stateConfig(\n",
    "    embed_key='state_emb', # our custom embedding key from above\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    output_path=\"yolksac_perturbed.h5ad\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c11cfb",
   "metadata": {},
   "source": [
    "Now we can run the perturbation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab93647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateTransitionModel\n",
    "\n",
    "state_transition = stateTransitionModel(configurer=config)\n",
    "\n",
    "# again we process the data and get the perturbed embeddings\n",
    "processed_data = state_transition.process_data(adata)\n",
    "perturbed_embeds = state_transition.get_embeddings(processed_data)\n",
    "\n",
    "print(perturbed_embeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582345dd",
   "metadata": {},
   "source": [
    "# Finetuning STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e835b83",
   "metadata": {},
   "source": [
    "We can finetune the STATE perturbation embeddings using an additional head for downstream classification and regression. Below is a dummy example using data above to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateFineTuningModel\n",
    "\n",
    "# Dummy cell types and labels for demonstration\n",
    "cell_types = list(adata.obs['LVL1'])\n",
    "label_set = set(cell_types)\n",
    "print(f\"Found {len(label_set)} unique cell types:\")\n",
    "\n",
    "config = stateConfig(\n",
    "    embed_key=\"state_emb\",  # Use gene expression instead of embeddings\n",
    "    pert_col=\"target_gene\",\n",
    "    celltype_col=\"cell_type\",\n",
    "    control_pert=\"[('DMSO_TF', 0.0, 'uM')]\",\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "# Create the fine-tuning model - we use a classification head for demonstration\n",
    "model = stateFineTuningModel(\n",
    "    configurer=config, \n",
    "    fine_tuning_head=\"classification\", \n",
    "    output_size=len(label_set),\n",
    ")\n",
    "\n",
    "# Process the data for training - returns a dataset object\n",
    "data = model.process_data(adata)\n",
    "\n",
    "# Create a dictionary mapping the classes to unique integers for training\n",
    "class_id_dict = dict(zip(label_set, [i for i in range(len(label_set))]))\n",
    "\n",
    "# Convert cell type labels to integers\n",
    "cell_type_labels = [class_id_dict[ct] for ct in cell_types]\n",
    "\n",
    "print(f\"Class mapping: {class_id_dict}\")\n",
    "\n",
    "# Fine-tune\n",
    "model.train(train_input_data=data, train_labels=cell_type_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53936df",
   "metadata": {},
   "source": [
    "# Training STATE for the Virtual Cell Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be814ae",
   "metadata": {},
   "source": [
    "We use data from the Virtual Cell Challenge for model training and downstream inference. For this we require the VCC dataset as in the colab notebook by the authors. See the relevant code snippet for the entire dataset in the below colab notebook:\n",
    "\n",
    "[STATE Colab Notebook](https://colab.research.google.com/drive/1QKOtYP7bMpdgDJEipDxaJqOchv7oQ-_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e7ad8",
   "metadata": {},
   "source": [
    "For demonstration we use a subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.utils.downloader import Downloader\n",
    "\n",
    "downloader = Downloader()\n",
    "downloader.download_via_name(\"sample_vcc_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974174ac",
   "metadata": {},
   "source": [
    "We use the `stateTransitionTrainModel` class and initialise `trainConfigs`. Be sure to edit the `competition/stater.toml` file to point to the correct dataset path (see top of file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateTransitionTrainModel\n",
    "from helical.models.state.train_configs import trainingConfig\n",
    "\n",
    "# default configs for competition dataset\n",
    "train_config = trainingConfig(\n",
    "    output_dir=\"competition\",\n",
    "    name=\"first_run\",\n",
    "    toml_config_path=\"competition_support_set/starter.toml\",\n",
    "    checkpoint_name=\"final.ckpt\",\n",
    "    max_steps=40000,\n",
    "    max_epochs=1,\n",
    "    ckpt_every_n_steps=20000,\n",
    "    num_workers=4,\n",
    "    batch_col=\"batch_var\",\n",
    "    pert_col=\"target_gene\",\n",
    "    cell_type_key=\"cell_type\",\n",
    "    control_pert=\"non-targeting\",\n",
    "    perturbation_features_file=\"competition_support_set/ESM2_pert_features.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23307fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then train the model and perform inference on a held out test set\n",
    "state_train = stateTransitionTrainModel(configurer=train_config)\n",
    "state_train.train() \n",
    "state_train.predict() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb512a0",
   "metadata": {},
   "source": [
    "The trained model will be saved to the `competition/first_run` directory, alongside the necessary files and checkpoints to intialise a new model. We can initialise `stateTransitionModel` as before and run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be67236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helical.models.state import stateTransitionModel\n",
    "\n",
    "adata = sc.read_h5ad(\"competition_support_set/validation_data.h5ad\")\n",
    "\n",
    "state_config = stateConfig(\n",
    "    output_path = \"competition/prediction.h5ad\",\n",
    "    model_dir = \"competition/first_run\",\n",
    "    pert_col = \"target_gene\",\n",
    ")\n",
    "\n",
    "state_transition = stateTransitionModel(configurer=state_config)\n",
    "processed_data = state_transition.process_data(adata)\n",
    "embeds = state_transition.get_embeddings(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45529597",
   "metadata": {},
   "source": [
    "Now you can use the `cell-eval` package to create a submission to the Virtual Cell Challenge. Helical provides a quicker wrapper around the main evaluation function that generates the `.vcc` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model - underlying function uses cell-eval package \n",
    "# (https://github.com/ArcInstitute/cell-eval)\n",
    "from helical.models.state import vcc_eval\n",
    "\n",
    "# default configs for competition dataset\n",
    "EXPECTED_GENE_DIM = 18080\n",
    "MAX_CELL_DIM = 100000\n",
    "DEFAULT_PERT_COL = \"target_gene\"\n",
    "DEFAULT_CTRL = \"non-targeting\"\n",
    "DEFAULT_COUNTS_COL = \"n_cells\"\n",
    "DEFAULT_CELLTYPE_COL = \"celltype\"\n",
    "DEFAULT_NTC_NAME = \"non-targeting\"\n",
    "\n",
    "configs = {\n",
    "    \"input\": \"competition/prediction.h5ad\",\n",
    "    \"genes\": \"competition_support_set/gene_names.csv\",\n",
    "    \"output\": None, # path to the output file - if None will be created with default naming\n",
    "    \"pert_col\": DEFAULT_PERT_COL,\n",
    "    \"celltype_col\": None,\n",
    "    \"ntc_name\": DEFAULT_NTC_NAME,\n",
    "    \"output_pert_col\": DEFAULT_PERT_COL,\n",
    "    \"output_celltype_col\": DEFAULT_CELLTYPE_COL,\n",
    "    \"encoding\": 32,\n",
    "    \"allow_discrete\": False,\n",
    "    \"expected_gene_dim\": EXPECTED_GENE_DIM,\n",
    "    \"max_cell_dim\": MAX_CELL_DIM,\n",
    "}\n",
    "\n",
    "# this creates a submission file in the output directory which can be uploaded to the challenge leaderboard\n",
    "vcc_eval(configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
