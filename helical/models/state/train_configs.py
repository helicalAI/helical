class trainingConfig:
    def __init__(
        self,
        toml_config_path: str = "competition_support_set/starter.toml",
        perturbation_features_file: str = "competition_support_set/ESM2_pert_features.pt",
        batch_size: int = 16,
        lr_rate: float = 0.0001,
        weight_decay: float = 0.0005,
        max_steps: int = None,
        max_epochs: int = 1000,
        train_seed: int = 42,
        val_freq: int = 2000,
        ckpt_every_n_steps: int = 20000,
        gradient_clip_val: int = 10,
        loss_fn: str = "mse",
        devices: int = 1,
        strategy: str = "auto",
        use_mfu: bool = True,
        num_workers: int = 4,
        batch_col: str = "batch_var",
        pert_col: str = "target_gene",
        cell_type_key: str = "cell_type",
        control_pert: str = "non-targeting",
        embed_key: str = None,
        model: str = "state",
        output_dir: str = "competition",
        name: str = "first_run",
        checkpoint_filename: str = "final.ckpt",
        predict_only: bool = False,
        results_dir: str = "competition/eval_final",
        profile: str = "full",
        device: str = "cuda",
    ):

        self.config = {
            "name": name,
            # we have to put checkpint last.cpkt in join(output_dir, name)
            "output_dir": output_dir,
            "checkpoint_filename": checkpoint_filename,
            "predict_only": predict_only,
            "profile": profile,
            "data": {
                "name": "PerturbationDataModule",
                "kwargs": {
                    "toml_config_path": toml_config_path,
                    "embed_key": embed_key,
                    "output_space": "all",
                    "pert_rep": "onehot",
                    "basal_rep": "sample",
                    "num_workers": num_workers,
                    "pin_memory": True,
                    "n_basal_samples": 1,
                    "basal_mapping_strategy": "random",
                    "should_yield_control_cells": True,
                    "batch_col": batch_col,
                    "pert_col": pert_col,
                    "cell_type_key": cell_type_key,
                    "control_pert": control_pert,
                    "map_controls": True,
                    "perturbation_features_file": perturbation_features_file,
                    "store_raw_basal": False,
                    "int_counts": False,
                    "barcode": True,
                },
                "output_dir": None,
                "debug": True,
            },
            "model": {
                "name": model,
                "checkpoint": None,
                "device": device,
                "kwargs": {
                    "cell_set_len": 128,
                    "blur": 0.05,
                    "hidden_dim": 672,
                    "loss": "energy",
                    "confidence_head": False,
                    "n_encoder_layers": 4,
                    "n_decoder_layers": 4,
                    "predict_residual": True,
                    "softplus": True,
                    "freeze_pert": False,
                    "transformer_decoder": False,
                    "finetune_vci_decoder": False,
                    "residual_decoder": False,
                    "batch_encoder": False,
                    "nb_decoder": False,
                    "mask_attn": False,
                    "use_effect_gating_token": False,
                    "use_basal_projection": False,
                    "distributional_loss": "energy",
                    "gene_decoder_bool": False,
                    "init_from": None,
                    "transformer_backbone_key": "llama",
                    "transformer_backbone_kwargs": {
                        "max_position_embeddings": 128,
                        "hidden_size": 672,
                        "intermediate_size": 2688,
                        "num_hidden_layers": 4,
                        "num_attention_heads": 8,
                        "num_key_value_heads": 8,
                        "head_dim": 84,
                        "use_cache": False,
                        "attention_dropout": 0.0,
                        "hidden_dropout": 0.0,
                        "layer_norm_eps": 1e-06,
                        "pad_token_id": 0,
                        "bos_token_id": 1,
                        "eos_token_id": 2,
                        "tie_word_embeddings": False,
                        "rotary_dim": 0,
                        "use_rotary_embeddings": False,
                    },
                },
            },
            "training": {
                # "wandb_track": True,
                "weight_decay": weight_decay,
                "batch_size": batch_size,
                "lr": lr_rate,
                "max_steps": max_steps,
                "max_epochs": max_epochs,
                "train_seed": train_seed,
                "val_freq": val_freq,
                "ckpt_every_n_steps": ckpt_every_n_steps,
                "gradient_clip_val": gradient_clip_val,
                "loss_fn": loss_fn,
                "devices": devices,
                "strategy": strategy, 
                "use_mfu": use_mfu,
                "mfu_kwargs": {
                    "available_flops": 60000000000000.0,
                    "use_backward": True,
                    "logging_interval": 10,
                    "window_size": 2,
                },
            },
        }
